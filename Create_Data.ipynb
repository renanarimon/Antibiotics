{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Organism group</th>\n",
       "      <th>Isolate</th>\n",
       "      <th>AMR genotypes</th>\n",
       "      <th>AST phenotypes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000077416.3</td>\n",
       "      <td>fosX=COMPLETE,lin=COMPLETE</td>\n",
       "      <td>chloramphenicol=S,clindamycin=R,erythromycin=S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000095192.3</td>\n",
       "      <td>fosX=COMPLETE,lin=COMPLETE</td>\n",
       "      <td>ampicillin=S,penicillin=S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salmonella enterica</td>\n",
       "      <td>PDT000003687.3</td>\n",
       "      <td>mdsA=COMPLETE,mdsB=COMPLETE</td>\n",
       "      <td>amikacin=S,amoxicillin-clavulanic acid=S,ampic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salmonella enterica</td>\n",
       "      <td>PDT000003688.4</td>\n",
       "      <td>mdsA=COMPLETE,mdsB=COMPLETE</td>\n",
       "      <td>amikacin=S,amoxicillin-clavulanic acid=S,ampic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salmonella enterica</td>\n",
       "      <td>PDT000003689.4</td>\n",
       "      <td>mdsA=COMPLETE,mdsB=COMPLETE</td>\n",
       "      <td>amikacin=S,amoxicillin-clavulanic acid=S,ampic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salmonella enterica</td>\n",
       "      <td>PDT000003690.3</td>\n",
       "      <td>aph(3'')-Ib=COMPLETE,aph(6)-Id=COMPLETE,mdsA=C...</td>\n",
       "      <td>amikacin=S,amoxicillin-clavulanic acid=S,ampic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Salmonella enterica</td>\n",
       "      <td>PDT000003691.3</td>\n",
       "      <td>mdsA=COMPLETE,mdsB=COMPLETE,tet(B)=COMPLETE</td>\n",
       "      <td>amikacin=S,amoxicillin-clavulanic acid=S,ampic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Salmonella enterica</td>\n",
       "      <td>PDT000003692.3</td>\n",
       "      <td>mdsA=COMPLETE,mdsB=COMPLETE</td>\n",
       "      <td>amikacin=S,amoxicillin-clavulanic acid=S,ampic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Salmonella enterica</td>\n",
       "      <td>PDT000003693.3</td>\n",
       "      <td>aph(3'')-Ib=COMPLETE,aph(6)-Id=COMPLETE,mdsA=C...</td>\n",
       "      <td>amikacin=S,amoxicillin-clavulanic acid=S,ampic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Salmonella enterica</td>\n",
       "      <td>PDT000003694.4</td>\n",
       "      <td>fosA7=COMPLETE,mdsA=COMPLETE,mdsB=COMPLETE</td>\n",
       "      <td>amikacin=S,amoxicillin-clavulanic acid=S,ampic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          #Organism group         Isolate  \\\n",
       "0  Listeria monocytogenes  PDT000077416.3   \n",
       "1  Listeria monocytogenes  PDT000095192.3   \n",
       "2     Salmonella enterica  PDT000003687.3   \n",
       "3     Salmonella enterica  PDT000003688.4   \n",
       "4     Salmonella enterica  PDT000003689.4   \n",
       "5     Salmonella enterica  PDT000003690.3   \n",
       "6     Salmonella enterica  PDT000003691.3   \n",
       "7     Salmonella enterica  PDT000003692.3   \n",
       "8     Salmonella enterica  PDT000003693.3   \n",
       "9     Salmonella enterica  PDT000003694.4   \n",
       "\n",
       "                                       AMR genotypes  \\\n",
       "0                         fosX=COMPLETE,lin=COMPLETE   \n",
       "1                         fosX=COMPLETE,lin=COMPLETE   \n",
       "2                        mdsA=COMPLETE,mdsB=COMPLETE   \n",
       "3                        mdsA=COMPLETE,mdsB=COMPLETE   \n",
       "4                        mdsA=COMPLETE,mdsB=COMPLETE   \n",
       "5  aph(3'')-Ib=COMPLETE,aph(6)-Id=COMPLETE,mdsA=C...   \n",
       "6        mdsA=COMPLETE,mdsB=COMPLETE,tet(B)=COMPLETE   \n",
       "7                        mdsA=COMPLETE,mdsB=COMPLETE   \n",
       "8  aph(3'')-Ib=COMPLETE,aph(6)-Id=COMPLETE,mdsA=C...   \n",
       "9         fosA7=COMPLETE,mdsA=COMPLETE,mdsB=COMPLETE   \n",
       "\n",
       "                                      AST phenotypes  \n",
       "0  chloramphenicol=S,clindamycin=R,erythromycin=S...  \n",
       "1                          ampicillin=S,penicillin=S  \n",
       "2  amikacin=S,amoxicillin-clavulanic acid=S,ampic...  \n",
       "3  amikacin=S,amoxicillin-clavulanic acid=S,ampic...  \n",
       "4  amikacin=S,amoxicillin-clavulanic acid=S,ampic...  \n",
       "5  amikacin=S,amoxicillin-clavulanic acid=S,ampic...  \n",
       "6  amikacin=S,amoxicillin-clavulanic acid=S,ampic...  \n",
       "7  amikacin=S,amoxicillin-clavulanic acid=S,ampic...  \n",
       "8  amikacin=S,amoxicillin-clavulanic acid=S,ampic...  \n",
       "9  amikacin=S,amoxicillin-clavulanic acid=S,ampic...  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"isolates.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def transform_dataframe(df):\n",
    "    new_data = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        # split AMR genotypes and remove \"=COMPLETE\"\n",
    "        amr_genotypes = [i.split('=')[0] for i in row['AMR genotypes'].split(',')]\n",
    "\n",
    "        # split AST phenotypes\n",
    "        ast_phenotypes = row['AST phenotypes'].split(',')\n",
    "\n",
    "        # process each phenotype\n",
    "        for pheno in ast_phenotypes:\n",
    "            drug, resistance = pheno.split('=')\n",
    "            if resistance == 'R':\n",
    "                resistance_score = 1\n",
    "            elif resistance == 'S':\n",
    "                resistance_score = 0\n",
    "            else:  # assuming 'I' as per your description\n",
    "                resistance_score = 0.5\n",
    "\n",
    "            # create a new row\n",
    "            new_row = {'#Organism group': row['#Organism group'],\n",
    "                       'Isolate': row['Isolate'],\n",
    "                       'AMR genotypes': ', '.join(amr_genotypes),\n",
    "                       'drug': drug,\n",
    "                       'resistance': resistance_score}\n",
    "            new_data.append(new_row)\n",
    "\n",
    "    # create a new dataframe\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = transform_dataframe(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Organism group</th>\n",
       "      <th>Isolate</th>\n",
       "      <th>AMR genotypes</th>\n",
       "      <th>drug</th>\n",
       "      <th>resistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000077416.3</td>\n",
       "      <td>fosX, lin</td>\n",
       "      <td>chloramphenicol</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000077416.3</td>\n",
       "      <td>fosX, lin</td>\n",
       "      <td>clindamycin</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000077416.3</td>\n",
       "      <td>fosX, lin</td>\n",
       "      <td>erythromycin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000077416.3</td>\n",
       "      <td>fosX, lin</td>\n",
       "      <td>gentamicin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000077416.3</td>\n",
       "      <td>fosX, lin</td>\n",
       "      <td>levofloxacin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000077416.3</td>\n",
       "      <td>fosX, lin</td>\n",
       "      <td>oxacillin</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000077416.3</td>\n",
       "      <td>fosX, lin</td>\n",
       "      <td>penicillin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000077416.3</td>\n",
       "      <td>fosX, lin</td>\n",
       "      <td>rifampin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000077416.3</td>\n",
       "      <td>fosX, lin</td>\n",
       "      <td>tetracycline</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Listeria monocytogenes</td>\n",
       "      <td>PDT000077416.3</td>\n",
       "      <td>fosX, lin</td>\n",
       "      <td>trimethoprim-sulfamethoxazole</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          #Organism group         Isolate AMR genotypes  \\\n",
       "0  Listeria monocytogenes  PDT000077416.3     fosX, lin   \n",
       "1  Listeria monocytogenes  PDT000077416.3     fosX, lin   \n",
       "2  Listeria monocytogenes  PDT000077416.3     fosX, lin   \n",
       "3  Listeria monocytogenes  PDT000077416.3     fosX, lin   \n",
       "4  Listeria monocytogenes  PDT000077416.3     fosX, lin   \n",
       "5  Listeria monocytogenes  PDT000077416.3     fosX, lin   \n",
       "6  Listeria monocytogenes  PDT000077416.3     fosX, lin   \n",
       "7  Listeria monocytogenes  PDT000077416.3     fosX, lin   \n",
       "8  Listeria monocytogenes  PDT000077416.3     fosX, lin   \n",
       "9  Listeria monocytogenes  PDT000077416.3     fosX, lin   \n",
       "\n",
       "                            drug  resistance  \n",
       "0                chloramphenicol         0.0  \n",
       "1                    clindamycin         1.0  \n",
       "2                   erythromycin         0.0  \n",
       "3                     gentamicin         0.0  \n",
       "4                   levofloxacin         0.0  \n",
       "5                      oxacillin         1.0  \n",
       "6                     penicillin         0.0  \n",
       "7                       rifampin         0.0  \n",
       "8                   tetracycline         0.0  \n",
       "9  trimethoprim-sulfamethoxazole         0.0  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316071, 5)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"BasicData.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chloramphenicol</th>\n",
       "      <th>dicloxacillin</th>\n",
       "      <th>ciprofloxacin</th>\n",
       "      <th>ceftiofur</th>\n",
       "      <th>fosfomycin-glucose-6-phosphate</th>\n",
       "      <th>amoxicillin-clavulanic acid</th>\n",
       "      <th>benzylpenicillin</th>\n",
       "      <th>metronidazole</th>\n",
       "      <th>linezolid</th>\n",
       "      <th>piperacillin</th>\n",
       "      <th>...</th>\n",
       "      <th>trimethoprim-sulfamethoxazole</th>\n",
       "      <th>aztreonam</th>\n",
       "      <th>norfloxacin</th>\n",
       "      <th>neomycin</th>\n",
       "      <th>Imipenem-EDTA-PA</th>\n",
       "      <th>delafloxacin</th>\n",
       "      <th>zoliflodacin</th>\n",
       "      <th>vancomycin</th>\n",
       "      <th>ertapenem</th>\n",
       "      <th>cefiderocol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qnrB48</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blaADC-155</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oqxB19</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blaACT-37</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blaTEM-19</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blaOXA-494</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qnrB38</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmexD3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tet(O)</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murA_D278E</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            chloramphenicol  dicloxacillin  ciprofloxacin  ceftiofur  \\\n",
       "qnrB48                   -1             -1             -1         -1   \n",
       "blaADC-155               -1             -1             -1         -1   \n",
       "oqxB19                   -1             -1             -1         -1   \n",
       "blaACT-37                -1             -1             -1         -1   \n",
       "blaTEM-19                -1             -1             -1         -1   \n",
       "...                     ...            ...            ...        ...   \n",
       "blaOXA-494               -1             -1             -1         -1   \n",
       "qnrB38                   -1             -1             -1         -1   \n",
       "tmexD3                   -1             -1             -1         -1   \n",
       "tet(O)                   -1             -1             -1         -1   \n",
       "murA_D278E               -1             -1             -1         -1   \n",
       "\n",
       "            fosfomycin-glucose-6-phosphate  amoxicillin-clavulanic acid  \\\n",
       "qnrB48                                  -1                           -1   \n",
       "blaADC-155                              -1                           -1   \n",
       "oqxB19                                  -1                           -1   \n",
       "blaACT-37                               -1                           -1   \n",
       "blaTEM-19                               -1                           -1   \n",
       "...                                    ...                          ...   \n",
       "blaOXA-494                              -1                           -1   \n",
       "qnrB38                                  -1                           -1   \n",
       "tmexD3                                  -1                           -1   \n",
       "tet(O)                                  -1                           -1   \n",
       "murA_D278E                              -1                           -1   \n",
       "\n",
       "            benzylpenicillin  metronidazole  linezolid  piperacillin  ...  \\\n",
       "qnrB48                    -1             -1         -1            -1  ...   \n",
       "blaADC-155                -1             -1         -1            -1  ...   \n",
       "oqxB19                    -1             -1         -1            -1  ...   \n",
       "blaACT-37                 -1             -1         -1            -1  ...   \n",
       "blaTEM-19                 -1             -1         -1            -1  ...   \n",
       "...                      ...            ...        ...           ...  ...   \n",
       "blaOXA-494                -1             -1         -1            -1  ...   \n",
       "qnrB38                    -1             -1         -1            -1  ...   \n",
       "tmexD3                    -1             -1         -1            -1  ...   \n",
       "tet(O)                    -1             -1         -1            -1  ...   \n",
       "murA_D278E                -1             -1         -1            -1  ...   \n",
       "\n",
       "            trimethoprim-sulfamethoxazole  aztreonam  norfloxacin  neomycin  \\\n",
       "qnrB48                                 -1         -1           -1        -1   \n",
       "blaADC-155                             -1         -1           -1        -1   \n",
       "oqxB19                                 -1         -1           -1        -1   \n",
       "blaACT-37                              -1         -1           -1        -1   \n",
       "blaTEM-19                              -1         -1           -1        -1   \n",
       "...                                   ...        ...          ...       ...   \n",
       "blaOXA-494                             -1         -1           -1        -1   \n",
       "qnrB38                                 -1         -1           -1        -1   \n",
       "tmexD3                                 -1         -1           -1        -1   \n",
       "tet(O)                                 -1         -1           -1        -1   \n",
       "murA_D278E                             -1         -1           -1        -1   \n",
       "\n",
       "            Imipenem-EDTA-PA  delafloxacin  zoliflodacin  vancomycin  \\\n",
       "qnrB48                    -1            -1            -1          -1   \n",
       "blaADC-155                -1            -1            -1          -1   \n",
       "oqxB19                    -1            -1            -1          -1   \n",
       "blaACT-37                 -1            -1            -1          -1   \n",
       "blaTEM-19                 -1            -1            -1          -1   \n",
       "...                      ...           ...           ...         ...   \n",
       "blaOXA-494                -1            -1            -1          -1   \n",
       "qnrB38                    -1            -1            -1          -1   \n",
       "tmexD3                    -1            -1            -1          -1   \n",
       "tet(O)                    -1            -1            -1          -1   \n",
       "murA_D278E                -1            -1            -1          -1   \n",
       "\n",
       "            ertapenem  cefiderocol  \n",
       "qnrB48             -1           -1  \n",
       "blaADC-155         -1           -1  \n",
       "oqxB19             -1           -1  \n",
       "blaACT-37          -1           -1  \n",
       "blaTEM-19          -1           -1  \n",
       "...               ...          ...  \n",
       "blaOXA-494         -1           -1  \n",
       "qnrB38             -1           -1  \n",
       "tmexD3             -1           -1  \n",
       "tet(O)             -1           -1  \n",
       "murA_D278E         -1           -1  \n",
       "\n",
       "[1213 rows x 114 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_all_genes = set()\n",
    "unique_all_antibiotics = set()\n",
    "\n",
    "def create_empty_gene_antibiotic_df(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        genotypes = row['AMR genotypes'].split(', ')\n",
    "        antibiotic = row['drug']\n",
    "        \n",
    "        unique_all_genes.update(genotypes)\n",
    "        unique_all_antibiotics.add(antibiotic)\n",
    "    \n",
    "    gene_antibiotic_df = pd.DataFrame(index=unique_all_genes, columns=unique_all_antibiotics)\n",
    "    gene_antibiotic_df = gene_antibiotic_df.fillna(-1)\n",
    "    \n",
    "    return gene_antibiotic_df\n",
    "\n",
    "# Assuming your DataFrame is named 'new_dataframe'\n",
    "gene_antibiotic_df = create_empty_gene_antibiotic_df(new_dataframe)\n",
    "gene_antibiotic_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gene_per_drug(drug):\n",
    "    drug_df = df[df['drug'] == drug]\n",
    "    unique_genes = set()\n",
    "    for genes in drug_df['AMR genotypes'].str.split(', '):\n",
    "        unique_genes.update(genes)\n",
    "    return drug_df, unique_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gene_df(drug_df, unique_genes):\n",
    "    gene_arrays = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, row in drug_df.iterrows():\n",
    "        gene_array = np.zeros(len(unique_genes), dtype=int)\n",
    "        genes = row['AMR genotypes'].split(', ')\n",
    "        for gene in genes:\n",
    "            gene_index = list(unique_genes).index(gene)\n",
    "            gene_array[gene_index] = 1\n",
    "\n",
    "        gene_arrays.append(gene_array.tolist())\n",
    "        labels.append(row['resistance'])\n",
    "\n",
    "    gene_df = pd.DataFrame(gene_arrays, columns=unique_genes)\n",
    "    gene_df['label'] = labels\n",
    "\n",
    "    return gene_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Model(drug_df_for_model):\n",
    "    # Assuming your DataFrame with gene features and labels is named `oxacillin_df_for_model`\n",
    "    # Split the data into features (genes) and labels\n",
    "    features = drug_df_for_model.drop('label', axis=1).values\n",
    "    labels = drug_df_for_model['label'].values\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the neural network model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(64, activation='relu', input_shape=(features.shape[1],)))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # Sigmoid activation for probability between 0 and 1\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, mse = model.evaluate(X_test, y_test)\n",
    "    pred = model.predict(X_test)\n",
    "    print('Loss:', loss)\n",
    "    print('Mean Squared Error:', mse)\n",
    "    print('len of pred: ', pred.shape, 'y_test: ', y_test.shape)\n",
    "    # Make predictions\n",
    "    return y_test, pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_test, predictions, drug):\n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    # Calculate mean absolute error\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    # Calculate R^2 score\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    \n",
    "    print('Mean Squared Error:', mse)\n",
    "    print('Mean Absolute Error:', mae)\n",
    "    print('R^2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_df_one_gene(drug_df_for_model):\n",
    "    # Extract the column names (excluding the label column)\n",
    "    column_names = drug_df_for_model.columns[:-1]\n",
    "\n",
    "    # Create a new DataFrame with zeros\n",
    "    df_one_gene = pd.DataFrame(0, index=np.arange(len(column_names)), columns=column_names)\n",
    "\n",
    "    # Set the value at the corresponding index position in each row\n",
    "    for i in range(len(column_names)):\n",
    "        df_one_gene.iloc[i, i] = 1\n",
    "\n",
    "    # Display the new DataFrame\n",
    "    return df_one_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredR_Antibiotic(drug):\n",
    "    print('************************\\n', drug)\n",
    "    \n",
    "    drug_df,drug_genes =   gene_per_drug(drug)\n",
    "    drug_df_for_model = create_gene_df(drug_df, drug_genes)\n",
    "    y_test, predictions, model = Model(drug_df_for_model)\n",
    "    evaluation(y_test, predictions, drug)\n",
    "    df_gene = Create_df_one_gene(drug_df_for_model)\n",
    "    pred = model.predict(df_gene)\n",
    "    for i, col in enumerate(df_gene.columns):\n",
    "        gene_antibiotic_df.loc[col, drug] = pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      " chloramphenicol\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.1426 - mse: 0.0345\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0531 - mse: 0.0066\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0473 - mse: 0.0053\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0444 - mse: 0.0047\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0433 - mse: 0.0046\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0420 - mse: 0.0043\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 0s 949us/step - loss: 0.0415 - mse: 0.0043\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 0s 880us/step - loss: 0.0412 - mse: 0.0042\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0405 - mse: 0.0041\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 0.0398 - mse: 0.0041\n",
      "77/77 [==============================] - 0s 684us/step - loss: 0.0631 - mse: 0.0078\n",
      "Loss: 0.06305903941392899\n",
      "Mean Squared Error: 0.00778650026768446\n",
      "len of pred:  (2455, 1) y_test:  (2455,)\n",
      "Mean Squared Error: 0.007786501268264286\n",
      "Mean Absolute Error: 0.016110380873614213\n",
      "R^2 Score: 0.8704039870475323\n",
      "************************\n",
      " ciprofloxacin\n",
      "Epoch 1/10\n",
      "533/533 [==============================] - 1s 1ms/step - loss: 0.1679 - mse: 0.0449\n",
      "Epoch 2/10\n",
      "533/533 [==============================] - 1s 1ms/step - loss: 0.0676 - mse: 0.0127\n",
      "Epoch 3/10\n",
      "533/533 [==============================] - 1s 1ms/step - loss: 0.0607 - mse: 0.0110\n",
      "Epoch 4/10\n",
      "533/533 [==============================] - 1s 1ms/step - loss: 0.0573 - mse: 0.0102\n",
      "Epoch 5/10\n",
      "533/533 [==============================] - 1s 1ms/step - loss: 0.0539 - mse: 0.0092\n",
      "Epoch 6/10\n",
      "533/533 [==============================] - 1s 1ms/step - loss: 0.0518 - mse: 0.0089\n",
      "Epoch 7/10\n",
      "533/533 [==============================] - 1s 1ms/step - loss: 0.0499 - mse: 0.0082\n",
      "Epoch 8/10\n",
      "533/533 [==============================] - 1s 1ms/step - loss: 0.0481 - mse: 0.0078\n",
      "Epoch 9/10\n",
      "533/533 [==============================] - 1s 1ms/step - loss: 0.0473 - mse: 0.0077\n",
      "Epoch 10/10\n",
      "533/533 [==============================] - 1s 1ms/step - loss: 0.0459 - mse: 0.0073\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0885 - mse: 0.0164\n",
      "Loss: 0.08848624676465988\n",
      "Mean Squared Error: 0.016445808112621307\n",
      "len of pred:  (4257, 1) y_test:  (4257,)\n",
      "Mean Squared Error: 0.016445806893712712\n",
      "Mean Absolute Error: 0.03268668112290046\n",
      "R^2 Score: 0.8977710567933166\n",
      "************************\n",
      " ceftiofur\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.3030 - mse: 0.0927\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.0506 - mse: 0.0084\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 0s 883us/step - loss: 0.0414 - mse: 0.0061\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 0s 883us/step - loss: 0.0374 - mse: 0.0056\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.0365 - mse: 0.0053\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 0s 907us/step - loss: 0.0364 - mse: 0.0055\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 0s 884us/step - loss: 0.0345 - mse: 0.0053\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 0s 903us/step - loss: 0.0334 - mse: 0.0050\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 0s 934us/step - loss: 0.0329 - mse: 0.0050\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 0.0328 - mse: 0.0049\n",
      "31/31 [==============================] - 0s 774us/step - loss: 0.0596 - mse: 0.0090\n",
      "Loss: 0.059577591717243195\n",
      "Mean Squared Error: 0.008957244455814362\n",
      "len of pred:  (971, 1) y_test:  (971,)\n",
      "Mean Squared Error: 0.008957242833154898\n",
      "Mean Absolute Error: 0.014518267332097594\n",
      "R^2 Score: 0.9316267737230131\n",
      "************************\n",
      " amoxicillin-clavulanic acid\n",
      "Epoch 1/10\n",
      "367/367 [==============================] - 0s 1ms/step - loss: 0.2529 - mse: 0.0585\n",
      "Epoch 2/10\n",
      "367/367 [==============================] - 0s 1ms/step - loss: 0.1273 - mse: 0.0177\n",
      "Epoch 3/10\n",
      "367/367 [==============================] - 0s 1ms/step - loss: 0.1173 - mse: 0.0151\n",
      "Epoch 4/10\n",
      "367/367 [==============================] - 0s 1ms/step - loss: 0.1126 - mse: 0.0136\n",
      "Epoch 5/10\n",
      "367/367 [==============================] - 0s 1ms/step - loss: 0.1101 - mse: 0.0133\n",
      "Epoch 6/10\n",
      "367/367 [==============================] - 0s 1ms/step - loss: 0.1083 - mse: 0.0126\n",
      "Epoch 7/10\n",
      "367/367 [==============================] - 0s 1ms/step - loss: 0.1054 - mse: 0.0121\n",
      "Epoch 8/10\n",
      "367/367 [==============================] - 0s 1ms/step - loss: 0.1043 - mse: 0.0118\n",
      "Epoch 9/10\n",
      "367/367 [==============================] - 0s 1ms/step - loss: 0.1031 - mse: 0.0116\n",
      "Epoch 10/10\n",
      "367/367 [==============================] - 0s 951us/step - loss: 0.1028 - mse: 0.0115\n",
      "92/92 [==============================] - 0s 689us/step - loss: 0.1255 - mse: 0.0164\n",
      "Loss: 0.12551043927669525\n",
      "Mean Squared Error: 0.016397414728999138\n",
      "len of pred:  (2932, 1) y_test:  (2932,)\n",
      "Mean Squared Error: 0.0163974156093895\n",
      "Mean Absolute Error: 0.04401761715674678\n",
      "R^2 Score: 0.8558074909919307\n",
      "************************\n",
      " benzylpenicillin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6201 - mse: 0.2136\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5875 - mse: 0.1975\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5579 - mse: 0.1831\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5327 - mse: 0.1710\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5085 - mse: 0.1595\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 286us/step - loss: 0.4868 - mse: 0.1493\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 985us/step - loss: 0.4657 - mse: 0.1395\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4444 - mse: 0.1299\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4236 - mse: 0.1206\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4027 - mse: 0.1115\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4129 - mse: 0.1152\n",
      "Loss: 0.41287076473236084\n",
      "Mean Squared Error: 0.11515375226736069\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 0.11515375691058871\n",
      "Mean Absolute Error: 0.3371136486530304\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " metronidazole\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6883 - mse: 0.0391\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6793 - mse: 0.0347\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6725 - mse: 0.0315\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6678 - mse: 0.0292\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6641 - mse: 0.0274\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 760us/step - loss: 0.6605 - mse: 0.0257\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6572 - mse: 0.0241\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6539 - mse: 0.0226\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6509 - mse: 0.0211\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6480 - mse: 0.0198\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7958 - mse: 0.1758\n",
      "Loss: 0.7958160638809204\n",
      "Mean Squared Error: 0.17575767636299133\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 0.17575767708870815\n",
      "Mean Absolute Error: 0.34564198553562164\n",
      "R^2 Score: -1.8121228334193304\n",
      "************************\n",
      " linezolid\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 0s 847us/step - loss: 0.4654 - mse: 0.1429\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 857us/step - loss: 0.2620 - mse: 0.0677\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 859us/step - loss: 0.1898 - mse: 0.0498\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 0s 904us/step - loss: 0.1448 - mse: 0.0384\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 898us/step - loss: 0.1201 - mse: 0.0334\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 898us/step - loss: 0.1039 - mse: 0.0300\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 909us/step - loss: 0.0924 - mse: 0.0276\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 906us/step - loss: 0.0822 - mse: 0.0250\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 0s 872us/step - loss: 0.0751 - mse: 0.0224\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 0s 878us/step - loss: 0.0662 - mse: 0.0188\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.0557 - mse: 0.0099\n",
      "Loss: 0.055715397000312805\n",
      "Mean Squared Error: 0.009895863011479378\n",
      "len of pred:  (168, 1) y_test:  (168,)\n",
      "Mean Squared Error: 0.009895862792818939\n",
      "Mean Absolute Error: 0.023048485401513323\n",
      "R^2 Score: 0.47671975369644637\n",
      "************************\n",
      " piperacillin\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.7483 - mse: 0.2565\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7073 - mse: 0.2362\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6793 - mse: 0.2222\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6570 - mse: 0.2111\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6369 - mse: 0.2012\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.6167 - mse: 0.1912\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 978us/step - loss: 0.5973 - mse: 0.1818\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 677us/step - loss: 0.5779 - mse: 0.1726\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5584 - mse: 0.1634\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5378 - mse: 0.1540\n",
      "WARNING:tensorflow:5 out of the last 101 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CAAFE94AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6619 - mse: 0.2338\n",
      "Loss: 0.6618738174438477\n",
      "Mean Squared Error: 0.2337503731250763\n",
      "len of pred:  (9, 1) y_test:  (9,)\n",
      "Mean Squared Error: 0.23375036433889523\n",
      "Mean Absolute Error: 0.46725347969267106\n",
      "R^2 Score: -0.05187663952502852\n",
      "************************\n",
      " moxifloxacin\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6707 - mse: 0.2284\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 912us/step - loss: 0.6176 - mse: 0.2025\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.5497 - mse: 0.1722\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 915us/step - loss: 0.4719 - mse: 0.1432\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 919us/step - loss: 0.4095 - mse: 0.1234\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 837us/step - loss: 0.3625 - mse: 0.1091\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 888us/step - loss: 0.3298 - mse: 0.0989\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 871us/step - loss: 0.3092 - mse: 0.0941\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.2946 - mse: 0.0907\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2835 - mse: 0.0869\n",
      "WARNING:tensorflow:6 out of the last 102 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CAB67CFEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3916 - mse: 0.1170\n",
      "Loss: 0.39162445068359375\n",
      "Mean Squared Error: 0.11697658151388168\n",
      "len of pred:  (97, 1) y_test:  (97,)\n",
      "Mean Squared Error: 0.11697656688893372\n",
      "Mean Absolute Error: 0.221393554173794\n",
      "R^2 Score: 0.4563435327942813\n",
      "************************\n",
      " ceftazidime-clavulanic acid\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6444 - mse: 0.0740\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5937 - mse: 0.0532\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5529 - mse: 0.0387\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5179 - mse: 0.0275\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4954 - mse: 0.0203\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4799 - mse: 0.0149\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4685 - mse: 0.0111\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4606 - mse: 0.0088\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4542 - mse: 0.0070\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4485 - mse: 0.0054\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.4980 - mse: 0.0110\n",
      "Loss: 0.49796217679977417\n",
      "Mean Squared Error: 0.010956873185932636\n",
      "len of pred:  (178, 1) y_test:  (178,)\n",
      "Mean Squared Error: 0.01095687379369669\n",
      "Mean Absolute Error: 0.045707564987684704\n",
      "R^2 Score: 0.846458385988728\n",
      "************************\n",
      " cefpodoxime\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 0s 861us/step - loss: 0.6600 - mse: 0.2335\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6236 - mse: 0.2157\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5813 - mse: 0.1961\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5369 - mse: 0.1777\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.4880 - mse: 0.1600\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4435 - mse: 0.1454\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 937us/step - loss: 0.4009 - mse: 0.1323\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 853us/step - loss: 0.3588 - mse: 0.1188\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3228 - mse: 0.1064\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 853us/step - loss: 0.2955 - mse: 0.0987\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3989 - mse: 0.1411\n",
      "Loss: 0.39894652366638184\n",
      "Mean Squared Error: 0.14108487963676453\n",
      "len of pred:  (56, 1) y_test:  (56,)\n",
      "Mean Squared Error: 0.14108486475754206\n",
      "Mean Absolute Error: 0.25356640773160116\n",
      "R^2 Score: 0.39803791036782055\n",
      "************************\n",
      " nitrofurantoin\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 0s 960us/step - loss: 0.5547 - mse: 0.1661\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2108 - mse: 0.0419\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1672 - mse: 0.0299\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1488 - mse: 0.0245\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 977us/step - loss: 0.1337 - mse: 0.0206\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 955us/step - loss: 0.1226 - mse: 0.0178\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 936us/step - loss: 0.1160 - mse: 0.0167\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1091 - mse: 0.0149\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1044 - mse: 0.0138\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1024 - mse: 0.0132\n",
      "10/10 [==============================] - 0s 970us/step - loss: 0.2458 - mse: 0.0547\n",
      "Loss: 0.2458273470401764\n",
      "Mean Squared Error: 0.0546860471367836\n",
      "len of pred:  (303, 1) y_test:  (303,)\n",
      "Mean Squared Error: 0.05468604532979819\n",
      "Mean Absolute Error: 0.09365488871162747\n",
      "R^2 Score: 0.7560116080338505\n",
      "************************\n",
      " clindamycin\n",
      "Epoch 1/10\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3998 - mse: 0.1232\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1705 - mse: 0.0456\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.1056 - mse: 0.0230\n",
      "Epoch 4/10\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0764 - mse: 0.0140\n",
      "Epoch 5/10\n",
      "92/92 [==============================] - 0s 996us/step - loss: 0.0718 - mse: 0.0129\n",
      "Epoch 6/10\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0679 - mse: 0.0122\n",
      "Epoch 7/10\n",
      "92/92 [==============================] - 0s 924us/step - loss: 0.0630 - mse: 0.0114\n",
      "Epoch 8/10\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0642 - mse: 0.0116\n",
      "Epoch 9/10\n",
      "92/92 [==============================] - 0s 951us/step - loss: 0.0602 - mse: 0.0111\n",
      "Epoch 10/10\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.0586 - mse: 0.0107\n",
      "23/23 [==============================] - 0s 768us/step - loss: 0.1430 - mse: 0.0296\n",
      "Loss: 0.14295119047164917\n",
      "Mean Squared Error: 0.029567478224635124\n",
      "len of pred:  (731, 1) y_test:  (731,)\n",
      "Mean Squared Error: 0.029567481516394947\n",
      "Mean Absolute Error: 0.040861862909798624\n",
      "R^2 Score: 0.6244914738842717\n",
      "************************\n",
      " tylosin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - mse: 8.2888e-05\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - mse: 1.5499e-05\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - mse: 2.8414e-05\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6932 - mse: 4.0753e-05\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - mse: 2.2198e-05\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - mse: 9.1266e-06\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 966us/step - loss: 0.6932 - mse: 2.7045e-06\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - mse: 6.6649e-06\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.6932 - mse: 1.6388e-05\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - mse: 1.6423e-05\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - mse: 1.0097e-05\n",
      "Loss: 0.6931673288345337\n",
      "Mean Squared Error: 1.0096913683810271e-05\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 1.0096913334312063e-05\n",
      "Mean Absolute Error: 0.003116592764854431\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " azithromycin\n",
      "Epoch 1/10\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.1012 - mse: 0.0239\n",
      "Epoch 2/10\n",
      "309/309 [==============================] - 0s 992us/step - loss: 0.0252 - mse: 0.0046\n",
      "Epoch 3/10\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.0179 - mse: 0.0027\n",
      "Epoch 4/10\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0019\n",
      "Epoch 5/10\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.0118 - mse: 0.0014\n",
      "Epoch 6/10\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 0.0011\n",
      "Epoch 7/10\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0010\n",
      "Epoch 8/10\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.0092 - mse: 8.5539e-04\n",
      "Epoch 9/10\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.0088 - mse: 9.1740e-04\n",
      "Epoch 10/10\n",
      "309/309 [==============================] - 0s 1ms/step - loss: 0.0089 - mse: 8.8709e-04\n",
      "78/78 [==============================] - 0s 729us/step - loss: 0.0354 - mse: 0.0043\n",
      "Loss: 0.03544260933995247\n",
      "Mean Squared Error: 0.00434123445302248\n",
      "len of pred:  (2468, 1) y_test:  (2468,)\n",
      "Mean Squared Error: 0.004341234514305741\n",
      "Mean Absolute Error: 0.006250243979174648\n",
      "R^2 Score: 0.6438711970873454\n",
      "************************\n",
      " cefotetan\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.6428 - mse: 0.2201\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5641 - mse: 0.1836\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4997 - mse: 0.1572\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4415 - mse: 0.1378\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 980us/step - loss: 0.4038 - mse: 0.1276\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3826 - mse: 0.1218\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3691 - mse: 0.1173\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.3584 - mse: 0.1133\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3483 - mse: 0.1094\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3371 - mse: 0.1043\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4216 - mse: 0.1470\n",
      "Loss: 0.42159503698349\n",
      "Mean Squared Error: 0.1469532698392868\n",
      "len of pred:  (45, 1) y_test:  (45,)\n",
      "Mean Squared Error: 0.14695325527940953\n",
      "Mean Absolute Error: 0.26583005785942077\n",
      "R^2 Score: 0.3787466765327676\n",
      "************************\n",
      " ampicillin-sulbactam\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5898 - mse: 0.1655\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3946 - mse: 0.0877\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3324 - mse: 0.0660\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2942 - mse: 0.0538\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 0s 889us/step - loss: 0.2722 - mse: 0.0467\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 0s 976us/step - loss: 0.2568 - mse: 0.0420\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 0s 976us/step - loss: 0.2444 - mse: 0.0390\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2379 - mse: 0.0371\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2434 - mse: 0.0386\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2288 - mse: 0.0346\n",
      "12/12 [==============================] - 0s 914us/step - loss: 0.3584 - mse: 0.0783\n",
      "Loss: 0.35844066739082336\n",
      "Mean Squared Error: 0.07833617180585861\n",
      "len of pred:  (367, 1) y_test:  (367,)\n",
      "Mean Squared Error: 0.07833617470741705\n",
      "Mean Absolute Error: 0.15993128201292386\n",
      "R^2 Score: 0.6284197557609685\n",
      "************************\n",
      " cefotaxime-clavulanic acid\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6794 - mse: 0.0939\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6363 - mse: 0.0735\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5897 - mse: 0.0548\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5474 - mse: 0.0396\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5136 - mse: 0.0284\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4934 - mse: 0.0221\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4746 - mse: 0.0156\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4643 - mse: 0.0127\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4534 - mse: 0.0089\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4446 - mse: 0.0066\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.4652 - mse: 0.0227\n",
      "Loss: 0.46521395444869995\n",
      "Mean Squared Error: 0.022657526656985283\n",
      "len of pred:  (180, 1) y_test:  (180,)\n",
      "Mean Squared Error: 0.022657526530231824\n",
      "Mean Absolute Error: 0.07954169298759048\n",
      "R^2 Score: 0.7768681277873827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      " cefalexin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6686 - mse: 0.2377\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6542 - mse: 0.2306\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6416 - mse: 0.2243\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6312 - mse: 0.2191\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6235 - mse: 0.2153\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6164 - mse: 0.2119\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6051 - mse: 0.2063\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5923 - mse: 0.1999\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5780 - mse: 0.1929\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5623 - mse: 0.1852\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6937 - mse: 2.5285e-04\n",
      "Loss: 0.6936531662940979\n",
      "Mean Squared Error: 0.0002528541081119329\n",
      "len of pred:  (1, 1) y_test:  (1,)\n",
      "Mean Squared Error: 0.00025285410018582866\n",
      "Mean Absolute Error: 0.015901386737823486\n",
      "R^2 Score: nan\n",
      "************************\n",
      " cefazolin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:589: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4121 - mse: 0.1158\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2437 - mse: 0.0542\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2089 - mse: 0.0438\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1941 - mse: 0.0400\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1826 - mse: 0.0369\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1775 - mse: 0.0359\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1733 - mse: 0.0349\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1666 - mse: 0.0330\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1629 - mse: 0.0321\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1598 - mse: 0.0314\n",
      "27/27 [==============================] - 0s 771us/step - loss: 0.2400 - mse: 0.0518\n",
      "Loss: 0.24001096189022064\n",
      "Mean Squared Error: 0.05183839052915573\n",
      "len of pred:  (840, 1) y_test:  (840,)\n",
      "Mean Squared Error: 0.05183838690301729\n",
      "Mean Absolute Error: 0.10464577391034081\n",
      "R^2 Score: 0.7780346791629293\n",
      "************************\n",
      " ceftazidime\n",
      "Epoch 1/10\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.4151 - mse: 0.1185\n",
      "Epoch 2/10\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.2330 - mse: 0.0540\n",
      "Epoch 3/10\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1946 - mse: 0.0424\n",
      "Epoch 4/10\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1732 - mse: 0.0365\n",
      "Epoch 5/10\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1583 - mse: 0.0323\n",
      "Epoch 6/10\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1478 - mse: 0.0292\n",
      "Epoch 7/10\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1411 - mse: 0.0275\n",
      "Epoch 8/10\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1355 - mse: 0.0257\n",
      "Epoch 9/10\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1323 - mse: 0.0250\n",
      "Epoch 10/10\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 0.1269 - mse: 0.0232\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.0895 - mse: 0.0203WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "37/37 [==============================] - 0s 815us/step - loss: 0.2685 - mse: 0.0588\n",
      "Loss: 0.2684631049633026\n",
      "Mean Squared Error: 0.058816853910684586\n",
      "len of pred:  (1158, 1) y_test:  (1158,)\n",
      "Mean Squared Error: 0.05881685390012083\n",
      "Mean Absolute Error: 0.10304216690040559\n",
      "R^2 Score: 0.7486350481453997\n",
      "************************\n",
      " polymyxin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7022 - mse: 0.2233\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6732 - mse: 0.2088\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6504 - mse: 0.1975\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6310 - mse: 0.1879\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6125 - mse: 0.1787\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5931 - mse: 0.1692\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5740 - mse: 0.1598\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5555 - mse: 0.1509\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5389 - mse: 0.1429\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5216 - mse: 0.1347\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6859 - mse: 0.2454\n",
      "Loss: 0.6859470009803772\n",
      "Mean Squared Error: 0.2454104870557785\n",
      "len of pred:  (3, 1) y_test:  (3,)\n",
      "Mean Squared Error: 0.2454104848183567\n",
      "Mean Absolute Error: 0.47641616066296893\n",
      "R^2 Score: -0.10434718168260493\n",
      "************************\n",
      " clarithromycin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.7427 - mse: 0.2748\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7138 - mse: 0.2603\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6854 - mse: 0.2461\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6648 - mse: 0.2359\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6448 - mse: 0.2259\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6267 - mse: 0.2169\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6112 - mse: 0.2092\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5999 - mse: 0.2037\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5903 - mse: 0.1989\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5806 - mse: 0.1942\n",
      "1/1 [==============================] - 0s 578us/step - loss: 0.6186 - mse: 0.2129\n",
      "Loss: 0.6185921430587769\n",
      "Mean Squared Error: 0.21285027265548706\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 0.21285027470543483\n",
      "Mean Absolute Error: 0.46094584465026855\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " tobramycin\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.4317 - mse: 0.1223\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2253 - mse: 0.0469\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1929 - mse: 0.0375\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1792 - mse: 0.0338\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1712 - mse: 0.0316\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1638 - mse: 0.0298\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1626 - mse: 0.0291\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1556 - mse: 0.0275\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1502 - mse: 0.0264\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1489 - mse: 0.0259\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1942 - mse: 0.0401\n",
      "Loss: 0.19416412711143494\n",
      "Mean Squared Error: 0.04012466222047806\n",
      "len of pred:  (1000, 1) y_test:  (1000,)\n",
      "Mean Squared Error: 0.04012465916538764\n",
      "Mean Absolute Error: 0.0881950126886186\n",
      "R^2 Score: 0.8075036590668339\n",
      "************************\n",
      " imipenem-relebactam\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.8249 - mse: 0.2912\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.7872 - mse: 0.2729\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7576 - mse: 0.2583\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.7320 - mse: 0.2456\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.7126 - mse: 0.2359\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7012 - mse: 0.2303\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6935 - mse: 0.2264\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6879 - mse: 0.2236\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6838 - mse: 0.2216\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6808 - mse: 0.2200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6997 - mse: 0.2533\n",
      "Loss: 0.6996521949768066\n",
      "Mean Squared Error: 0.253251850605011\n",
      "len of pred:  (6, 1) y_test:  (6,)\n",
      "Mean Squared Error: 0.25325183865248\n",
      "Mean Absolute Error: 0.5031362821658453\n",
      "R^2 Score: -0.13963327393615987\n",
      "************************\n",
      " sulfamethoxazole\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 997us/step - loss: 0.6737 - mse: 0.2391\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6049 - mse: 0.2060\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4826 - mse: 0.1527\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 839us/step - loss: 0.3294 - mse: 0.0905\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 997us/step - loss: 0.1789 - mse: 0.0366\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 915us/step - loss: 0.0901 - mse: 0.0156\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 916us/step - loss: 0.0567 - mse: 0.0098\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 937us/step - loss: 0.0436 - mse: 0.0080\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 849us/step - loss: 0.0397 - mse: 0.0074\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 842us/step - loss: 0.0363 - mse: 0.0066\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1120 - mse: 0.0232\n",
      "Loss: 0.1120484247803688\n",
      "Mean Squared Error: 0.02324584499001503\n",
      "len of pred:  (157, 1) y_test:  (157,)\n",
      "Mean Squared Error: 0.023245844758988197\n",
      "Mean Absolute Error: 0.03945184873927171\n",
      "R^2 Score: 0.9028506565845541\n",
      "************************\n",
      " teicoplanin\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 999us/step - loss: 0.5851 - mse: 0.1964\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4478 - mse: 0.1315\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2998 - mse: 0.0718\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1792 - mse: 0.0368\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1096 - mse: 0.0249\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0843 - mse: 0.0219\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0726 - mse: 0.0203\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0658 - mse: 0.0187\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0623 - mse: 0.0179\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0591 - mse: 0.0169\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0425 - mse: 0.0116\n",
      "Loss: 0.04249093309044838\n",
      "Mean Squared Error: 0.011640968732535839\n",
      "len of pred:  (59, 1) y_test:  (59,)\n",
      "Mean Squared Error: 0.011640969891969503\n",
      "Mean Absolute Error: 0.02966857209043988\n",
      "R^2 Score: 0.3013411001043822\n",
      "************************\n",
      " oxytetracycline\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6976 - mse: 0.2522\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6907 - mse: 0.2488\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6862 - mse: 0.2465\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6816 - mse: 0.2443\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6769 - mse: 0.2419\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6722 - mse: 0.2395\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6674 - mse: 0.2372\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6628 - mse: 0.2349\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6587 - mse: 0.2328\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 957us/step - loss: 0.6556 - mse: 0.2313\n",
      "WARNING:tensorflow:5 out of the last 41 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CAD0C3A940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 955us/step - loss: 0.6499 - mse: 0.2284\n",
      "Loss: 0.6499327421188354\n",
      "Mean Squared Error: 0.22843167185783386\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 0.22843166284019745\n",
      "Mean Absolute Error: 0.47763824462890625\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " rifampin\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 0s 956us/step - loss: 0.6403 - mse: 0.2210\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4669 - mse: 0.1400\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2684 - mse: 0.0687\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2056 - mse: 0.0521\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1582 - mse: 0.0404\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1360 - mse: 0.0362\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1218 - mse: 0.0325\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1122 - mse: 0.0297\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1014 - mse: 0.0262\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0921 - mse: 0.0234\n",
      "WARNING:tensorflow:6 out of the last 42 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA8D67C0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "6/6 [==============================] - 0s 824us/step - loss: 0.1897 - mse: 0.0434\n",
      "Loss: 0.1896512806415558\n",
      "Mean Squared Error: 0.0433802604675293\n",
      "len of pred:  (165, 1) y_test:  (165,)\n",
      "Mean Squared Error: 0.04338025950387608\n",
      "Mean Absolute Error: 0.07371443817083315\n",
      "R^2 Score: 0.14727251625052262\n",
      "************************\n",
      " tetracycline\n",
      "Epoch 1/10\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.2019 - mse: 0.0529\n",
      "Epoch 2/10\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.0942 - mse: 0.0169A: 0s - loss: 0.0934 - mse: 0.\n",
      "Epoch 3/10\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.0860 - mse: 0.0147\n",
      "Epoch 4/10\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.0835 - mse: 0.0142\n",
      "Epoch 5/10\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.0800 - mse: 0.0134\n",
      "Epoch 6/10\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.0779 - mse: 0.0128\n",
      "Epoch 7/10\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.0762 - mse: 0.0125\n",
      "Epoch 8/10\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.0748 - mse: 0.0122\n",
      "Epoch 9/10\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.0732 - mse: 0.0118\n",
      "Epoch 10/10\n",
      "509/509 [==============================] - 1s 1ms/step - loss: 0.0724 - mse: 0.0118\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CABC699790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "128/128 [==============================] - 0s 751us/step - loss: 0.1073 - mse: 0.0188\n",
      "Loss: 0.107270248234272\n",
      "Mean Squared Error: 0.01876024529337883\n",
      "len of pred:  (4071, 1) y_test:  (4071,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.018760241075123092\n",
      "Mean Absolute Error: 0.034180899688729435\n",
      "R^2 Score: 0.9234305849625694\n",
      "************************\n",
      " cefoxitin\n",
      "Epoch 1/10\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.1851 - mse: 0.0481\n",
      "Epoch 2/10\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.0886 - mse: 0.0163\n",
      "Epoch 3/10\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.0807 - mse: 0.0142\n",
      "Epoch 4/10\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.0749 - mse: 0.0124\n",
      "Epoch 5/10\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.0716 - mse: 0.0119\n",
      "Epoch 6/10\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.0690 - mse: 0.0111\n",
      "Epoch 7/10\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.0645 - mse: 0.0100\n",
      "Epoch 8/10\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.0629 - mse: 0.0096\n",
      "Epoch 9/10\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.0615 - mse: 0.0092\n",
      "Epoch 10/10\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.0593 - mse: 0.0087\n",
      "88/88 [==============================] - 0s 862us/step - loss: 0.1103 - mse: 0.0200\n",
      "Loss: 0.11033368110656738\n",
      "Mean Squared Error: 0.020015127956867218\n",
      "len of pred:  (2785, 1) y_test:  (2785,)\n",
      "Mean Squared Error: 0.020015126899787943\n",
      "Mean Absolute Error: 0.03934879588502143\n",
      "R^2 Score: 0.8580929637020556\n",
      "************************\n",
      " chlortetracycline\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.8938 - mse: 0.2856\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8471 - mse: 0.2634\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.8040 - mse: 0.2425\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7678 - mse: 0.2247\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7336 - mse: 0.2077\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.7035 - mse: 0.1927\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6755 - mse: 0.1787\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6520 - mse: 0.1670\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6461 - mse: 0.1640\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6447 - mse: 0.1633\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6187 - mse: 0.2128\n",
      "Loss: 0.6186875104904175\n",
      "Mean Squared Error: 0.21284550428390503\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 0.21284550833183724\n",
      "Mean Absolute Error: 0.46133242547512054\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " sulfisoxazole\n",
      "Epoch 1/10\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.1782 - mse: 0.0505\n",
      "Epoch 2/10\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0654 - mse: 0.0121\n",
      "Epoch 3/10\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0621 - mse: 0.0117\n",
      "Epoch 4/10\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0613 - mse: 0.0115\n",
      "Epoch 5/10\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0595 - mse: 0.0113\n",
      "Epoch 6/10\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0595 - mse: 0.0114\n",
      "Epoch 7/10\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0587 - mse: 0.0114\n",
      "Epoch 8/10\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0574 - mse: 0.0111\n",
      "Epoch 9/10\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0579 - mse: 0.0112\n",
      "Epoch 10/10\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.0568 - mse: 0.0111\n",
      " 1/70 [..............................] - ETA: 0s - loss: 0.0100 - mse: 1.5913e-04WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "70/70 [==============================] - 0s 742us/step - loss: 0.0568 - mse: 0.0099\n",
      "Loss: 0.05679643526673317\n",
      "Mean Squared Error: 0.00989160779863596\n",
      "len of pred:  (2231, 1) y_test:  (2231,)\n",
      "Mean Squared Error: 0.009891608932389424\n",
      "Mean Absolute Error: 0.021893705452939314\n",
      "R^2 Score: 0.9512807564386299\n",
      "************************\n",
      " netilmicin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6765 - mse: 0.1792\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6672 - mse: 0.1745\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6583 - mse: 0.1701\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6493 - mse: 0.1657\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 978us/step - loss: 0.6401 - mse: 0.1611\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6316 - mse: 0.1570\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6230 - mse: 0.1527\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6146 - mse: 0.1487\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6048 - mse: 0.1439\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5948 - mse: 0.1391\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7055 - mse: 0.2557\n",
      "Loss: 0.7055314183235168\n",
      "Mean Squared Error: 0.25574880838394165\n",
      "len of pred:  (3, 1) y_test:  (3,)\n",
      "Mean Squared Error: 0.25574881715793296\n",
      "Mean Absolute Error: 0.5001189510027567\n",
      "R^2 Score: -0.1508696772106981\n",
      "************************\n",
      " amikacin\n",
      "Epoch 1/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.2274 - mse: 0.0629\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1049 - mse: 0.0226\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0837 - mse: 0.0163\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0760 - mse: 0.0142\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0709 - mse: 0.0128\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0657 - mse: 0.0119\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0622 - mse: 0.0108\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0615 - mse: 0.0108\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0584 - mse: 0.0100\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0574 - mse: 0.0100\n",
      "52/52 [==============================] - 0s 741us/step - loss: 0.1819 - mse: 0.0323\n",
      "Loss: 0.18188415467739105\n",
      "Mean Squared Error: 0.032311126589775085\n",
      "len of pred:  (1658, 1) y_test:  (1658,)\n",
      "Mean Squared Error: 0.03231111879041405\n",
      "Mean Absolute Error: 0.04907037744323873\n",
      "R^2 Score: 0.6447886714400104\n",
      "************************\n",
      " trimethoprim\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 831us/step - loss: 0.6889 - mse: 0.2472\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6731 - mse: 0.2393\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 953us/step - loss: 0.6533 - mse: 0.2297\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 997us/step - loss: 0.6254 - mse: 0.2167\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5909 - mse: 0.2020\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5524 - mse: 0.1869\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5122 - mse: 0.1717\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 907us/step - loss: 0.4743 - mse: 0.1580\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4334 - mse: 0.1414\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 816us/step - loss: 0.3870 - mse: 0.1219\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.3888 - mse: 0.1234\n",
      "Loss: 0.38883960247039795\n",
      "Mean Squared Error: 0.12342908978462219\n",
      "len of pred:  (87, 1) y_test:  (87,)\n",
      "Mean Squared Error: 0.12342909407549749\n",
      "Mean Absolute Error: 0.28155632128660707\n",
      "R^2 Score: 0.48284815219626875\n",
      "************************\n",
      " colistin\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5706 - mse: 0.1030\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4458 - mse: 0.0559\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4020 - mse: 0.0439\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3726 - mse: 0.0352\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3515 - mse: 0.0288\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3358 - mse: 0.0242\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3266 - mse: 0.0217\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3175 - mse: 0.0188\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3134 - mse: 0.0180\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3058 - mse: 0.0159\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4726 - mse: 0.041 - 0s 830us/step - loss: 0.4888 - mse: 0.0508\n",
      "Loss: 0.4887636601924896\n",
      "Mean Squared Error: 0.050790123641490936\n",
      "len of pred:  (376, 1) y_test:  (376,)\n",
      "Mean Squared Error: 0.05079012488012053\n",
      "Mean Absolute Error: 0.11330102159091261\n",
      "R^2 Score: 0.46155974016820045\n",
      "************************\n",
      " cefalotin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.7205 - mse: 0.2637\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 954us/step - loss: 0.6950 - mse: 0.2509\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6725 - mse: 0.2397\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6484 - mse: 0.2277\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6248 - mse: 0.2160\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6037 - mse: 0.2056\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5866 - mse: 0.1973\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5725 - mse: 0.1905\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5578 - mse: 0.1834\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5439 - mse: 0.1768\n",
      "1/1 [==============================] - 0s 985us/step - loss: 0.4759 - mse: 0.1434\n",
      "Loss: 0.47588735818862915\n",
      "Mean Squared Error: 0.14339540898799896\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 0.1433954086487148\n",
      "Mean Absolute Error: 0.3786519765853882\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " doripenem\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6568 - mse: 0.2155\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5051 - mse: 0.1463\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3673 - mse: 0.0934\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2901 - mse: 0.0687\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.2386 - mse: 0.0534\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1989 - mse: 0.0411\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1784 - mse: 0.0361\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1585 - mse: 0.0301\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1511 - mse: 0.0284\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1377 - mse: 0.0252\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.3306 - mse: 0.0895\n",
      "Loss: 0.3306127190589905\n",
      "Mean Squared Error: 0.08954421430826187\n",
      "len of pred:  (251, 1) y_test:  (251,)\n",
      "Mean Squared Error: 0.08954422234073499\n",
      "Mean Absolute Error: 0.14219858803122168\n",
      "R^2 Score: 0.628282176279864\n",
      "************************\n",
      " meropenem\n",
      "Epoch 1/10\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 0.2002 - mse: 0.0580\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 0.0739 - mse: 0.0188\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 0.0607 - mse: 0.0149\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 0.0528 - mse: 0.0124\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 0.0472 - mse: 0.0108\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 0.0448 - mse: 0.0103\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 0.0412 - mse: 0.0092\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 0.0391 - mse: 0.0090\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0079\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 0.0335 - mse: 0.0073\n",
      "76/76 [==============================] - 0s 864us/step - loss: 0.0841 - mse: 0.0177\n",
      "Loss: 0.08409928530454636\n",
      "Mean Squared Error: 0.0177057683467865\n",
      "len of pred:  (2401, 1) y_test:  (2401,)\n",
      "Mean Squared Error: 0.017705771192821504\n",
      "Mean Absolute Error: 0.029411066759194592\n",
      "R^2 Score: 0.7954797108667824\n",
      "************************\n",
      " carbenicillin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.7149 - mse: 0.2233\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.7020 - mse: 0.2169\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6915 - mse: 0.2117\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 327us/step - loss: 0.6826 - mse: 0.2072\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6746 - mse: 0.2033\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6672 - mse: 0.1996\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6603 - mse: 0.1961\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 976us/step - loss: 0.6533 - mse: 0.1926\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6472 - mse: 0.1896\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6406 - mse: 0.1863\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7051 - mse: 0.2059\n",
      "Loss: 0.7050573229789734\n",
      "Mean Squared Error: 0.20594045519828796\n",
      "len of pred:  (5, 1) y_test:  (5,)\n",
      "Mean Squared Error: 0.20594046726310822\n",
      "Mean Absolute Error: 0.40989410877227783\n",
      "R^2 Score: -0.02970233631554109\n",
      "************************\n",
      " penicillin\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 0s 858us/step - loss: 0.5407 - mse: 0.1423\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 0s 983us/step - loss: 0.4258 - mse: 0.1002\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 0s 950us/step - loss: 0.3418 - mse: 0.0650\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2619 - mse: 0.0359\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2270 - mse: 0.0260\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 0s 979us/step - loss: 0.2092 - mse: 0.0217\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.0928 - mse: 0.003 - 0s 1ms/step - loss: 0.2007 - mse: 0.0203\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1938 - mse: 0.0196\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1874 - mse: 0.0181\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 0s 930us/step - loss: 0.1827 - mse: 0.0174\n",
      "9/9 [==============================] - 0s 781us/step - loss: 0.2550 - mse: 0.0430\n",
      "Loss: 0.25503504276275635\n",
      "Mean Squared Error: 0.04303654283285141\n",
      "len of pred:  (264, 1) y_test:  (264,)\n",
      "Mean Squared Error: 0.04303654716958535\n",
      "Mean Absolute Error: 0.0906056844149575\n",
      "R^2 Score: 0.788112800824285\n",
      "************************\n",
      " daptomycin\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 900us/step - loss: 0.5936 - mse: 0.1923\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 931us/step - loss: 0.3721 - mse: 0.0933\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 845us/step - loss: 0.2437 - mse: 0.0540\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1970 - mse: 0.0457\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1699 - mse: 0.0395\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1493 - mse: 0.0351\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 997us/step - loss: 0.1383 - mse: 0.0329\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 946us/step - loss: 0.1308 - mse: 0.0308\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 980us/step - loss: 0.1212 - mse: 0.0280\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 918us/step - loss: 0.1160 - mse: 0.0263\n",
      "5/5 [==============================] - 0s 807us/step - loss: 0.2122 - mse: 0.0482\n",
      "Loss: 0.21221891045570374\n",
      "Mean Squared Error: 0.04823889583349228\n",
      "len of pred:  (131, 1) y_test:  (131,)\n",
      "Mean Squared Error: 0.0482388964614257\n",
      "Mean Absolute Error: 0.0897803302029617\n",
      "R^2 Score: 0.18319910984259846\n",
      "************************\n",
      " sulbactam\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9987 - mse: 0.3988\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.9545 - mse: 0.3782\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.9170 - mse: 0.3603\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.8844 - mse: 0.3446\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8584 - mse: 0.3320\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8350 - mse: 0.3205\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.8136 - mse: 0.3100\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7945 - mse: 0.3005\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.7794 - mse: 0.2930\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7658 - mse: 0.2863\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7472 - mse: 0.2770\n",
      "Loss: 0.7471866011619568\n",
      "Mean Squared Error: 0.2769944667816162\n",
      "len of pred:  (1, 1) y_test:  (1,)\n",
      "Mean Squared Error: 0.27699446431288166\n",
      "Mean Absolute Error: 0.5263026356697083\n",
      "R^2 Score: nan\n",
      "************************\n",
      " sulfonamide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:589: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6639 - mse: 0.2354\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.6522 - mse: 0.2295\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6414 - mse: 0.2241\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6304 - mse: 0.2187\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6192 - mse: 0.2131\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6088 - mse: 0.2079\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5978 - mse: 0.2025\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5809 - mse: 0.1941\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5597 - mse: 0.1837\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5351 - mse: 0.1717\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5295 - mse: 0.1690\n",
      "Loss: 0.529464602470398\n",
      "Mean Squared Error: 0.16898661851882935\n",
      "len of pred:  (1, 1) y_test:  (1,)\n",
      "Mean Squared Error: 0.16898662167585954\n",
      "Mean Absolute Error: 0.4110798239707947\n",
      "R^2 Score: nan\n",
      "************************\n",
      " cephalothin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:589: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.6587 - mse: 0.2068\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 940us/step - loss: 0.6075 - mse: 0.1826\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5564 - mse: 0.1615\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5127 - mse: 0.1454\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4662 - mse: 0.1282\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4238 - mse: 0.1123\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3756 - mse: 0.0949\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 856us/step - loss: 0.3317 - mse: 0.0800\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2910 - mse: 0.0633\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2562 - mse: 0.0498\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CAB7EF1430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.3555 - mse: 0.0768\n",
      "Loss: 0.35553932189941406\n",
      "Mean Squared Error: 0.07682547718286514\n",
      "len of pred:  (67, 1) y_test:  (67,)\n",
      "Mean Squared Error: 0.0768254751744014\n",
      "Mean Absolute Error: 0.17253452094633187\n",
      "R^2 Score: 0.5535669151354202\n",
      "************************\n",
      " sulfadimethoxine\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6933 - mse: 6.7940e-05\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6934 - mse: 1.4359e-04\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - mse: 4.0177e-05\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6932 - mse: 3.0760e-05\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - mse: 6.5086e-05\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6932 - mse: 4.3919e-05\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6932 - mse: 1.0792e-05\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6932 - mse: 1.2164e-05\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - mse: 2.9690e-05\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - mse: 2.6107e-05\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CAD025F4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 966us/step - loss: 0.6932 - mse: 3.6004e-06\n",
      "Loss: 0.6931543946266174\n",
      "Mean Squared Error: 3.6004025787406135e-06\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 3.600402639136746e-06\n",
      "Mean Absolute Error: 0.0016491413116455078\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " ampicillin\n",
      "Epoch 1/10\n",
      "410/410 [==============================] - 0s 988us/step - loss: 0.1821 - mse: 0.0499\n",
      "Epoch 2/10\n",
      "410/410 [==============================] - 0s 956us/step - loss: 0.0715 - mse: 0.0134\n",
      "Epoch 3/10\n",
      "410/410 [==============================] - 0s 1ms/step - loss: 0.0664 - mse: 0.0123\n",
      "Epoch 4/10\n",
      "410/410 [==============================] - 0s 990us/step - loss: 0.0625 - mse: 0.0117\n",
      "Epoch 5/10\n",
      "410/410 [==============================] - 0s 1ms/step - loss: 0.0601 - mse: 0.0109\n",
      "Epoch 6/10\n",
      "410/410 [==============================] - 1s 1ms/step - loss: 0.0582 - mse: 0.0108\n",
      "Epoch 7/10\n",
      "410/410 [==============================] - 1s 1ms/step - loss: 0.0577 - mse: 0.0106\n",
      "Epoch 8/10\n",
      "410/410 [==============================] - 1s 1ms/step - loss: 0.0569 - mse: 0.0105\n",
      "Epoch 9/10\n",
      "410/410 [==============================] - 1s 1ms/step - loss: 0.0551 - mse: 0.0102\n",
      "Epoch 10/10\n",
      "410/410 [==============================] - 0s 1ms/step - loss: 0.0546 - mse: 0.0102\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA9487DC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "103/103 [==============================] - 0s 804us/step - loss: 0.0859 - mse: 0.0151\n",
      "Loss: 0.08591552078723907\n",
      "Mean Squared Error: 0.015141676180064678\n",
      "len of pred:  (3275, 1) y_test:  (3275,)\n",
      "Mean Squared Error: 0.015141674482295317\n",
      "Mean Absolute Error: 0.024782619560292908\n",
      "R^2 Score: 0.9359396070363875\n",
      "************************\n",
      " temocillin\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 850us/step - loss: 0.5924 - mse: 0.2000\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.4216 - mse: 0.1197\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 938us/step - loss: 0.2404 - mse: 0.0506\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1222 - mse: 0.0186\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0748 - mse: 0.0119\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0695 - mse: 0.0110\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0665 - mse: 0.0109\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0644 - mse: 0.0109\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0615 - mse: 0.0109\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0584 - mse: 0.0108\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0127 - mse: 3.2380e-04\n",
      "Loss: 0.012703096494078636\n",
      "Mean Squared Error: 0.00032380232005380094\n",
      "len of pred:  (68, 1) y_test:  (68,)\n",
      "Mean Squared Error: 0.0003238022928371537\n",
      "Mean Absolute Error: 0.012537373777698068\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " danofloxacin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6626 - mse: 0.2347\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6293 - mse: 0.2181\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5968 - mse: 0.2020\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5657 - mse: 0.1868\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5374 - mse: 0.1731\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5077 - mse: 0.1590\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4808 - mse: 0.1465\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4546 - mse: 0.1346\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4290 - mse: 0.1233\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.4031 - mse: 0.1121\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3751 - mse: 0.0993\n",
      "Loss: 0.37511545419692993\n",
      "Mean Squared Error: 0.0992983877658844\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 0.09929838948460556\n",
      "Mean Absolute Error: 0.3108494281768799\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " cefuroxime\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.6730 - mse: 0.2349\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 872us/step - loss: 0.6347 - mse: 0.2158\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.5916 - mse: 0.1946\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 908us/step - loss: 0.5327 - mse: 0.1665\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 950us/step - loss: 0.4619 - mse: 0.1351\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 920us/step - loss: 0.3845 - mse: 0.1058\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 877us/step - loss: 0.3204 - mse: 0.0860\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 972us/step - loss: 0.2659 - mse: 0.0701\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2253 - mse: 0.0582\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 988us/step - loss: 0.1944 - mse: 0.0491\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.2283 - mse: 0.0607\n",
      "Loss: 0.228299081325531\n",
      "Mean Squared Error: 0.060718417167663574\n",
      "len of pred:  (62, 1) y_test:  (62,)\n",
      "Mean Squared Error: 0.06071841643443077\n",
      "Mean Absolute Error: 0.13911722360118742\n",
      "R^2 Score: 0.7114937048529643\n",
      "************************\n",
      " tulathromycin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6921 - mse: 0.2495\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 984us/step - loss: 0.6735 - mse: 0.2402\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6555 - mse: 0.2312\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6418 - mse: 0.2244\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6293 - mse: 0.2182\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6175 - mse: 0.2123\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6058 - mse: 0.2066\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5944 - mse: 0.2010\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5830 - mse: 0.1954\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5719 - mse: 0.1900\n",
      "WARNING:tensorflow:5 out of the last 110 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CAB6131E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5373 - mse: 0.1728\n",
      "Loss: 0.5373148918151855\n",
      "Mean Squared Error: 0.17282292246818542\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 0.1728229128561054\n",
      "Mean Absolute Error: 0.41559898853302\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " erythromycin\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.4036 - mse: 0.1251\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0959 - mse: 0.0219\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0547 - mse: 0.0106\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0479 - mse: 0.0094\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0075\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0393 - mse: 0.0074\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0396 - mse: 0.0076\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0374 - mse: 0.0070\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0365 - mse: 0.0070\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0360 - mse: 0.0069\n",
      "WARNING:tensorflow:6 out of the last 111 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA8D260790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "24/24 [==============================] - 0s 831us/step - loss: 0.0586 - mse: 0.0104\n",
      "Loss: 0.05861511081457138\n",
      "Mean Squared Error: 0.010414063930511475\n",
      "len of pred:  (765, 1) y_test:  (765,)\n",
      "Mean Squared Error: 0.010414063858906523\n",
      "Mean Absolute Error: 0.019849249101650986\n",
      "R^2 Score: 0.8756501938967677\n",
      "************************\n",
      " cefepime\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6366 - mse: 0.2107\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.5525 - mse: 0.1739\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.4935 - mse: 0.1482\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2975 - mse: 0.0752\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2189 - mse: 0.0521\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1960 - mse: 0.0460\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1846 - mse: 0.0426\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1692 - mse: 0.0380\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1592 - mse: 0.0352\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1533 - mse: 0.0332\n",
      " 1/32 [..............................] - ETA: 0s - loss: 0.1657 - mse: 0.0570WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.3079 - mse: 0.0737\n",
      "Loss: 0.3079161047935486\n",
      "Mean Squared Error: 0.07371752709150314\n",
      "len of pred:  (998, 1) y_test:  (998,)\n",
      "Mean Squared Error: 0.07371752235832828\n",
      "Mean Absolute Error: 0.1325630146015017\n",
      "R^2 Score: 0.6500903231173958\n",
      "************************\n",
      " ceftolozane-tazobactam\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 915us/step - loss: 0.6847 - mse: 0.2319\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 933us/step - loss: 0.6482 - mse: 0.2142\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6035 - mse: 0.1949\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5599 - mse: 0.1776\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 997us/step - loss: 0.5203 - mse: 0.1635\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4888 - mse: 0.1523\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4603 - mse: 0.1418\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4304 - mse: 0.1302\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3969 - mse: 0.1154\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3445 - mse: 0.0931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 998us/step - loss: 0.4452 - mse: 0.1292\n",
      "Loss: 0.4451563060283661\n",
      "Mean Squared Error: 0.12919485569000244\n",
      "len of pred:  (90, 1) y_test:  (90,)\n",
      "Mean Squared Error: 0.12919484921694216\n",
      "Mean Absolute Error: 0.2903639045026567\n",
      "R^2 Score: 0.4616881282627411\n",
      "************************\n",
      " quinupristin-dalfopristin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7075 - mse: 0.2574\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6891 - mse: 0.2484\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6748 - mse: 0.2413\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6607 - mse: 0.2343\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 966us/step - loss: 0.6471 - mse: 0.2275\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6333 - mse: 0.2207\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6209 - mse: 0.2146\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6098 - mse: 0.2092\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5990 - mse: 0.2039\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5891 - mse: 0.1991\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6355 - mse: 0.1717\n",
      "Loss: 0.6355189681053162\n",
      "Mean Squared Error: 0.17169161140918732\n",
      "len of pred:  (5, 1) y_test:  (5,)\n",
      "Mean Squared Error: 0.17169161122920934\n",
      "Mean Absolute Error: 0.37114242315292356\n",
      "R^2 Score: -0.0730725701825583\n",
      "************************\n",
      " tiamulin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6938 - mse: 3.4239e-04\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6934 - mse: 1.5088e-04\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6932 - mse: 3.3587e-05\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - mse: 2.5986e-06\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6932 - mse: 5.2463e-06\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6932 - mse: 6.3074e-06\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6932 - mse: 5.8725e-06\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6932 - mse: 5.2510e-06\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6932 - mse: 4.1786e-06\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6932 - mse: 2.9791e-06\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - mse: 2.9392e-07\n",
      "Loss: 0.6931477785110474\n",
      "Mean Squared Error: 2.939221417364024e-07\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 2.9392214884182977e-07\n",
      "Mean Absolute Error: 0.0005219578742980957\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " fusidic acid\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 0s 855us/step - loss: 0.8011 - mse: 0.3036\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 852us/step - loss: 0.6858 - mse: 0.2463\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6620 - mse: 0.2344\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6487 - mse: 0.2278\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 854us/step - loss: 0.6315 - mse: 0.2192\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 712us/step - loss: 0.6094 - mse: 0.2083\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5803 - mse: 0.1940\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 848us/step - loss: 0.5388 - mse: 0.1738\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.4859 - mse: 0.1488\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 855us/step - loss: 0.4142 - mse: 0.1169\n",
      "WARNING:tensorflow:5 out of the last 38 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CAA76D54C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3935 - mse: 0.1088\n",
      "Loss: 0.39347895979881287\n",
      "Mean Squared Error: 0.10882649570703506\n",
      "len of pred:  (55, 1) y_test:  (55,)\n",
      "Mean Squared Error: 0.10882650237750607\n",
      "Mean Absolute Error: 0.3152148994532498\n",
      "R^2 Score: -1.1102574980253586\n",
      "************************\n",
      " ceftriaxone\n",
      "Epoch 1/10\n",
      "419/419 [==============================] - 1s 1ms/step - loss: 0.2078 - mse: 0.0603\n",
      "Epoch 2/10\n",
      "419/419 [==============================] - 1s 1ms/step - loss: 0.0574 - mse: 0.0106\n",
      "Epoch 3/10\n",
      "419/419 [==============================] - 1s 1ms/step - loss: 0.0491 - mse: 0.0085\n",
      "Epoch 4/10\n",
      "419/419 [==============================] - 1s 1ms/step - loss: 0.0458 - mse: 0.0077\n",
      "Epoch 5/10\n",
      "419/419 [==============================] - 1s 1ms/step - loss: 0.0430 - mse: 0.0071\n",
      "Epoch 6/10\n",
      "419/419 [==============================] - 1s 1ms/step - loss: 0.0414 - mse: 0.0068\n",
      "Epoch 7/10\n",
      "419/419 [==============================] - 1s 1ms/step - loss: 0.0398 - mse: 0.0065\n",
      "Epoch 8/10\n",
      "419/419 [==============================] - 1s 1ms/step - loss: 0.0394 - mse: 0.0067\n",
      "Epoch 9/10\n",
      "419/419 [==============================] - 0s 1ms/step - loss: 0.0386 - mse: 0.0063\n",
      "Epoch 10/10\n",
      "419/419 [==============================] - 0s 1ms/step - loss: 0.0365 - mse: 0.0058\n",
      "WARNING:tensorflow:6 out of the last 40 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CAB75294C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "105/105 [==============================] - 0s 809us/step - loss: 0.0642 - mse: 0.0108\n",
      "WARNING:tensorflow:5 out of the last 27 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CAA7A3C040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Loss: 0.06418967247009277\n",
      "Mean Squared Error: 0.010841620154678822\n",
      "len of pred:  (3350, 1) y_test:  (3350,)\n",
      "Mean Squared Error: 0.010841617881455561\n",
      "Mean Absolute Error: 0.02145404614784513\n",
      "R^2 Score: 0.9346778371568498\n",
      "************************\n",
      " ticarcillin-clavulanic acid\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7474 - mse: 0.2682\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.7163 - mse: 0.2526\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6959 - mse: 0.2425\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.6875 - mse: 0.2383\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.6826 - mse: 0.2358\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6796 - mse: 0.2343\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6772 - mse: 0.2331\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6749 - mse: 0.2320\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.6720 - mse: 0.2306\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6697 - mse: 0.2294\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6662 - mse: 0.2366\n",
      "Loss: 0.6661899089813232\n",
      "Mean Squared Error: 0.2366127073764801\n",
      "len of pred:  (15, 1) y_test:  (15,)\n",
      "Mean Squared Error: 0.2366126927537285\n",
      "Mean Absolute Error: 0.48566083908081054\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " gentamicin\n",
      "Epoch 1/10\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.1818 - mse: 0.0457\n",
      "Epoch 2/10\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.0965 - mse: 0.0180\n",
      "Epoch 3/10\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.0878 - mse: 0.0157\n",
      "Epoch 4/10\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.0834 - mse: 0.0146\n",
      "Epoch 5/10\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.0800 - mse: 0.0138\n",
      "Epoch 6/10\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.0781 - mse: 0.0134\n",
      "Epoch 7/10\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.0755 - mse: 0.0128\n",
      "Epoch 8/10\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.0738 - mse: 0.0125\n",
      "Epoch 9/10\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.0720 - mse: 0.0123\n",
      "Epoch 10/10\n",
      "520/520 [==============================] - 1s 1ms/step - loss: 0.0710 - mse: 0.0120\n",
      "130/130 [==============================] - 0s 899us/step - loss: 0.1134 - mse: 0.0189\n",
      "Loss: 0.11337442696094513\n",
      "Mean Squared Error: 0.018868878483772278\n",
      "len of pred:  (4159, 1) y_test:  (4159,)\n",
      "Mean Squared Error: 0.018868876967685272\n",
      "Mean Absolute Error: 0.037545050553288224\n",
      "R^2 Score: 0.8553235991208604\n",
      "************************\n",
      " oxacillin\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 0s 981us/step - loss: 0.6878 - mse: 0.2473\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 939us/step - loss: 0.6618 - mse: 0.2344\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 939us/step - loss: 0.6170 - mse: 0.2126\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 998us/step - loss: 0.5254 - mse: 0.1695\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 957us/step - loss: 0.3589 - mse: 0.0980\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2150 - mse: 0.0550\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1633 - mse: 0.0441\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1406 - mse: 0.0385\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1231 - mse: 0.0329\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1119 - mse: 0.0304\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1908 - mse: 0.0550\n",
      "Loss: 0.19076071679592133\n",
      "Mean Squared Error: 0.05496927350759506\n",
      "len of pred:  (130, 1) y_test:  (130,)\n",
      "Mean Squared Error: 0.054969276112092555\n",
      "Mean Absolute Error: 0.1058766761651406\n",
      "R^2 Score: 0.7097842029695832\n",
      "************************\n",
      " telithromycin\n",
      "Epoch 1/10\n",
      "60/60 [==============================] - 0s 869us/step - loss: 0.3088 - mse: 0.0854\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 0s 917us/step - loss: 0.1182 - mse: 0.0233\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 0s 961us/step - loss: 0.0826 - mse: 0.0198\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 0s 990us/step - loss: 0.0550 - mse: 0.0134\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0437 - mse: 0.0100\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0383 - mse: 0.0083\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0344 - mse: 0.0070\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0313 - mse: 0.0065\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 0s 986us/step - loss: 0.0301 - mse: 0.0062\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 0s 979us/step - loss: 0.0294 - mse: 0.0061\n",
      "15/15 [==============================] - 0s 732us/step - loss: 0.0470 - mse: 0.0102\n",
      "Loss: 0.04701874032616615\n",
      "Mean Squared Error: 0.01020727027207613\n",
      "len of pred:  (477, 1) y_test:  (477,)\n",
      "Mean Squared Error: 0.010207269263860216\n",
      "Mean Absolute Error: 0.016317180385312723\n",
      "R^2 Score: 0.6149784866815564\n",
      "************************\n",
      " imipenem\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.3478 - mse: 0.1007\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.1734 - mse: 0.0421\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.1413 - mse: 0.0320\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.1318 - mse: 0.0296\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.1169 - mse: 0.0257\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.1105 - mse: 0.0237\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.1014 - mse: 0.0213\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.1007 - mse: 0.0211\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0968 - mse: 0.0198\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.0928 - mse: 0.0187\n",
      "34/34 [==============================] - 0s 837us/step - loss: 0.2291 - mse: 0.0512\n",
      "Loss: 0.22908669710159302\n",
      "Mean Squared Error: 0.05119599401950836\n",
      "len of pred:  (1065, 1) y_test:  (1065,)\n",
      "Mean Squared Error: 0.05119599240554599\n",
      "Mean Absolute Error: 0.0861402046558451\n",
      "R^2 Score: 0.7116099235109725\n",
      "************************\n",
      " streptomycin\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 0.2633 - mse: 0.0751\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 0.1688 - mse: 0.0421\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 0.1616 - mse: 0.0397\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 0.1583 - mse: 0.0389\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 0.1541 - mse: 0.0378\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 0.1526 - mse: 0.0375\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 0.1501 - mse: 0.0367\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 0.1486 - mse: 0.0362\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 0.1462 - mse: 0.0357\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 0.1460 - mse: 0.0356\n",
      "73/73 [==============================] - 0s 990us/step - loss: 0.1719 - mse: 0.0407\n",
      "Loss: 0.17189474403858185\n",
      "Mean Squared Error: 0.040678560733795166\n",
      "len of pred:  (2306, 1) y_test:  (2306,)\n",
      "Mean Squared Error: 0.040678556018542485\n",
      "Mean Absolute Error: 0.08623662364813729\n",
      "R^2 Score: 0.8231134237276511\n",
      "************************\n",
      " piperacillin-tazobactam\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4210 - mse: 0.1170\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2444 - mse: 0.0564\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2134 - mse: 0.0462\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1966 - mse: 0.0404\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1840 - mse: 0.0371\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1737 - mse: 0.0334\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1674 - mse: 0.0322\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1587 - mse: 0.0298\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1536 - mse: 0.0285\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.1463 - mse: 0.0266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 882us/step - loss: 0.3626 - mse: 0.0738\n",
      "Loss: 0.3626193404197693\n",
      "Mean Squared Error: 0.07381698489189148\n",
      "len of pred:  (866, 1) y_test:  (866,)\n",
      "Mean Squared Error: 0.07381697677672178\n",
      "Mean Absolute Error: 0.12430518713590488\n",
      "R^2 Score: 0.5880109425523454\n",
      "************************\n",
      " polymyxin B\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6885 - mse: 0.1230\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6511 - mse: 0.1045\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5868 - mse: 0.0745\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5289 - mse: 0.0534\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5050 - mse: 0.0458\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4877 - mse: 0.0416\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4752 - mse: 0.0381\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4646 - mse: 0.0347\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4582 - mse: 0.0331\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4490 - mse: 0.0300\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.4596 - mse: 0.0265\n",
      "Loss: 0.4595767557621002\n",
      "Mean Squared Error: 0.026539338752627373\n",
      "len of pred:  (181, 1) y_test:  (181,)\n",
      "Mean Squared Error: 0.026539339201568847\n",
      "Mean Absolute Error: 0.09735782386848281\n",
      "R^2 Score: 0.6529120592484643\n",
      "************************\n",
      " tilmicosin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - mse: 2.9904e-05\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6932 - mse: 1.1189e-05\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - mse: 1.1934e-05\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - mse: 7.5381e-06\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 963us/step - loss: 0.6932 - mse: 4.4118e-06\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6932 - mse: 4.0460e-06\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 966us/step - loss: 0.6932 - mse: 3.7408e-06\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6932 - mse: 2.0832e-06\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.6931 - mse: 5.0648e-07\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6931 - mse: 2.7313e-07\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - mse: 1.0083e-06\n",
      "Loss: 0.693149209022522\n",
      "Mean Squared Error: 1.0082978860737057e-06\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 1.0082979153835936e-06\n",
      "Mean Absolute Error: 0.000994950532913208\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " nalidixic acid\n",
      "Epoch 1/10\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.1483 - mse: 0.0401\n",
      "Epoch 2/10\n",
      "371/371 [==============================] - 1s 1ms/step - loss: 0.0382 - mse: 0.0077\n",
      "Epoch 3/10\n",
      "371/371 [==============================] - 1s 1ms/step - loss: 0.0300 - mse: 0.0059\n",
      "Epoch 4/10\n",
      "371/371 [==============================] - 1s 1ms/step - loss: 0.0259 - mse: 0.0051\n",
      "Epoch 5/10\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.0233 - mse: 0.0045\n",
      "Epoch 6/10\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.0215 - mse: 0.0042\n",
      "Epoch 7/10\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.0204 - mse: 0.0038\n",
      "Epoch 8/10\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.0192 - mse: 0.0036\n",
      "Epoch 9/10\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0036\n",
      "Epoch 10/10\n",
      "371/371 [==============================] - 0s 1ms/step - loss: 0.0189 - mse: 0.0035\n",
      "93/93 [==============================] - 0s 788us/step - loss: 0.0468 - mse: 0.0092\n",
      "Loss: 0.04679715633392334\n",
      "Mean Squared Error: 0.00916147418320179\n",
      "len of pred:  (2966, 1) y_test:  (2966,)\n",
      "Mean Squared Error: 0.009161473933793655\n",
      "Mean Absolute Error: 0.017801256336017306\n",
      "R^2 Score: 0.8980604777476819\n",
      "************************\n",
      " cefixime\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 997us/step - loss: 0.3264 - mse: 0.0760\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 913us/step - loss: 0.1600 - mse: 0.0248\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 918us/step - loss: 0.1395 - mse: 0.0224\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 997us/step - loss: 0.1220 - mse: 0.0209\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 836us/step - loss: 0.1110 - mse: 0.0190\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 938us/step - loss: 0.0993 - mse: 0.0168\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 917us/step - loss: 0.0903 - mse: 0.0152\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0826 - mse: 0.0131\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0780 - mse: 0.0119\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0731 - mse: 0.0105\n",
      "3/3 [==============================] - 0s 999us/step - loss: 0.1025 - mse: 0.0152\n",
      "Loss: 0.10248837620019913\n",
      "Mean Squared Error: 0.015247778967022896\n",
      "len of pred:  (94, 1) y_test:  (94,)\n",
      "Mean Squared Error: 0.015247778087766247\n",
      "Mean Absolute Error: 0.03456486539637789\n",
      "R^2 Score: 0.24732197104188536\n",
      "************************\n",
      " ceftazidime-avibactam\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6701 - mse: 0.2321\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5981 - mse: 0.1971\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5040 - mse: 0.1557\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4162 - mse: 0.1234\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3315 - mse: 0.0921\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2572 - mse: 0.0652\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2067 - mse: 0.0506\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1737 - mse: 0.0417\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1487 - mse: 0.0340\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1301 - mse: 0.0313\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4063 - mse: 0.1123\n",
      "Loss: 0.40634697675704956\n",
      "Mean Squared Error: 0.11232288181781769\n",
      "len of pred:  (99, 1) y_test:  (99,)\n",
      "Mean Squared Error: 0.11232289475479919\n",
      "Mean Absolute Error: 0.194559749930796\n",
      "R^2 Score: 0.4827922520592969\n",
      "************************\n",
      " ticarcillin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.7378 - mse: 0.2723\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7227 - mse: 0.2647\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.7086 - mse: 0.2577\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6976 - mse: 0.2522\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6889 - mse: 0.2479\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6811 - mse: 0.2440\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6741 - mse: 0.2405\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6678 - mse: 0.2374\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 968us/step - loss: 0.6623 - mse: 0.2346\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6572 - mse: 0.2320\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6529 - mse: 0.2299\n",
      "Loss: 0.6529312133789062\n",
      "Mean Squared Error: 0.22991494834423065\n",
      "len of pred:  (7, 1) y_test:  (7,)\n",
      "Mean Squared Error: 0.22991495779715773\n",
      "Mean Absolute Error: 0.479341379233769\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " plazomicin\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6834 - mse: 0.2308\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 498us/step - loss: 0.6485 - mse: 0.2137\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 997us/step - loss: 0.6232 - mse: 0.2016\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6003 - mse: 0.1910\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 498us/step - loss: 0.5805 - mse: 0.1822\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.5613 - mse: 0.1740\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.5424 - mse: 0.1660\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5248 - mse: 0.1586\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5080 - mse: 0.1516\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.4913 - mse: 0.1447\n",
      "WARNING:tensorflow:5 out of the last 102 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CACF7BECA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6630 - mse: 0.2077\n",
      "Loss: 0.6629818081855774\n",
      "Mean Squared Error: 0.20767971873283386\n",
      "len of pred:  (9, 1) y_test:  (9,)\n",
      "Mean Squared Error: 0.20767972717566727\n",
      "Mean Absolute Error: 0.42555905050701565\n",
      "R^2 Score: 0.06544122770949734\n",
      "************************\n",
      " cefotaxime\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.4385 - mse: 0.1317\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.2828 - mse: 0.0775\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1794 - mse: 0.0394\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1250 - mse: 0.0236\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1060 - mse: 0.0181\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0967 - mse: 0.0159\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0850 - mse: 0.0129\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0772 - mse: 0.0112\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0740 - mse: 0.0101\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0711 - mse: 0.0098\n",
      "WARNING:tensorflow:6 out of the last 103 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CAD022BD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "17/17 [==============================] - 0s 882us/step - loss: 0.1937 - mse: 0.0425\n",
      "Loss: 0.19371429085731506\n",
      "Mean Squared Error: 0.04253482073545456\n",
      "len of pred:  (525, 1) y_test:  (525,)\n",
      "Mean Squared Error: 0.04253482067401421\n",
      "Mean Absolute Error: 0.07140247552596043\n",
      "R^2 Score: 0.7372937615928838\n",
      "************************\n",
      " ceftaroline\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.5884 - mse: 0.1976\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4055 - mse: 0.1164\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.3058 - mse: 0.0830\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2640 - mse: 0.0729\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2370 - mse: 0.0659\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2092 - mse: 0.0580\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1874 - mse: 0.0513\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1649 - mse: 0.0450\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1452 - mse: 0.0400\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1265 - mse: 0.0345\n",
      "3/3 [==============================] - 0s 999us/step - loss: 0.2588 - mse: 0.0753\n",
      "Loss: 0.2588144540786743\n",
      "Mean Squared Error: 0.0753331109881401\n",
      "len of pred:  (72, 1) y_test:  (72,)\n",
      "Mean Squared Error: 0.0753331172106953\n",
      "Mean Absolute Error: 0.13233901146385404\n",
      "R^2 Score: 0.04223941233539086\n",
      "************************\n",
      " fosfomycin\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6925 - mse: 0.2156\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.6793 - mse: 0.2090\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.6635 - mse: 0.2011\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.6404 - mse: 0.1897\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6187 - mse: 0.1790\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.5923 - mse: 0.1661\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.5643 - mse: 0.1529\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.5330 - mse: 0.1385\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4979 - mse: 0.1228\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4644 - mse: 0.1084\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4931 - mse: 0.1459\n",
      "Loss: 0.49305644631385803\n",
      "Mean Squared Error: 0.14585961401462555\n",
      "len of pred:  (28, 1) y_test:  (28,)\n",
      "Mean Squared Error: 0.14585961483660523\n",
      "Mean Absolute Error: 0.3403546277965818\n",
      "R^2 Score: -0.15801456234833933\n",
      "************************\n",
      " florfenicol\n",
      "Epoch 1/10\n",
      "68/68 [==============================] - 0s 970us/step - loss: 0.6336 - mse: 0.2200\n",
      "Epoch 2/10\n",
      "68/68 [==============================] - 0s 997us/step - loss: 0.1408 - mse: 0.0293\n",
      "Epoch 3/10\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0136 - mse: 9.7330e-04\n",
      "Epoch 4/10\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0110 - mse: 9.1137e-04\n",
      "Epoch 5/10\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 8.6160e-04\n",
      "Epoch 6/10\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0088 - mse: 7.9091e-04\n",
      "Epoch 7/10\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0080 - mse: 7.1301e-04\n",
      "Epoch 8/10\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0074 - mse: 6.5406e-04\n",
      "Epoch 9/10\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0069 - mse: 5.9940e-04\n",
      "Epoch 10/10\n",
      "68/68 [==============================] - 0s 1000us/step - loss: 0.0063 - mse: 5.7859e-04\n",
      "17/17 [==============================] - 0s 704us/step - loss: 0.0170 - mse: 0.0014  \n",
      "Loss: 0.017006322741508484\n",
      "Mean Squared Error: 0.0013767307391390204\n",
      "len of pred:  (539, 1) y_test:  (539,)\n",
      "Mean Squared Error: 0.0013767307487851817\n",
      "Mean Absolute Error: 0.003564193823238178\n",
      "R^2 Score: 0.502835060450193\n",
      "************************\n",
      " kanamycin\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 0s 899us/step - loss: 0.3871 - mse: 0.1162\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 0s 988us/step - loss: 0.1042 - mse: 0.0197\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.0878 - mse: 0.0164\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.0844 - mse: 0.0152\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.0821 - mse: 0.0150\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 1ms/step - loss: 0.0805 - mse: 0.0148\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.0805 - mse: 0.0146\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.0772 - mse: 0.0144\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.0768 - mse: 0.0142\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.0778 - mse: 0.0143\n",
      "25/25 [==============================] - 0s 699us/step - loss: 0.0828 - mse: 0.0157\n",
      "Loss: 0.08277582377195358\n",
      "Mean Squared Error: 0.015682848170399666\n",
      "len of pred:  (778, 1) y_test:  (778,)\n",
      "Mean Squared Error: 0.01568284871164675\n",
      "Mean Absolute Error: 0.03337469662522902\n",
      "R^2 Score: 0.8543664412759745\n",
      "************************\n",
      " tigecycline\n",
      "Epoch 1/10\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4759 - mse: 0.1214\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.2609 - mse: 0.0429\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.2293 - mse: 0.0364\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.2121 - mse: 0.0327\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.1970 - mse: 0.0295\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.1841 - mse: 0.0268\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.1714 - mse: 0.0233\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.1626 - mse: 0.0214\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.1545 - mse: 0.0190\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.1464 - mse: 0.0164\n",
      "14/14 [==============================] - 0s 784us/step - loss: 0.2830 - mse: 0.0385\n",
      "Loss: 0.28303879499435425\n",
      "Mean Squared Error: 0.03854838013648987\n",
      "len of pred:  (442, 1) y_test:  (442,)\n",
      "Mean Squared Error: 0.03854837632031747\n",
      "Mean Absolute Error: 0.0865854001913532\n",
      "R^2 Score: 0.30113539426108915\n",
      "************************\n",
      " minocycline\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6889 - mse: 0.1909\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6423 - mse: 0.1677\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5328 - mse: 0.1176\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3896 - mse: 0.0674\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3190 - mse: 0.0484\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2917 - mse: 0.0407\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2715 - mse: 0.0331\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2581 - mse: 0.0289\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2463 - mse: 0.0247\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2424 - mse: 0.0242\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.3625 - mse: 0.0646\n",
      "Loss: 0.3624809682369232\n",
      "Mean Squared Error: 0.06455957144498825\n",
      "len of pred:  (154, 1) y_test:  (154,)\n",
      "Mean Squared Error: 0.06455956808440648\n",
      "Mean Absolute Error: 0.1431731151544985\n",
      "R^2 Score: 0.517955224969765\n",
      "************************\n",
      " levofloxacin\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3634 - mse: 0.1031\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1655 - mse: 0.0334\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1412 - mse: 0.0270\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1288 - mse: 0.0232\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1207 - mse: 0.0214\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1160 - mse: 0.0204\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1097 - mse: 0.0183\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1042 - mse: 0.0168\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1007 - mse: 0.0163\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0977 - mse: 0.0149\n",
      "34/34 [==============================] - 0s 874us/step - loss: 0.1959 - mse: 0.0391\n",
      "Loss: 0.19588911533355713\n",
      "Mean Squared Error: 0.039140522480010986\n",
      "len of pred:  (1076, 1) y_test:  (1076,)\n",
      "Mean Squared Error: 0.039140520930136015\n",
      "Mean Absolute Error: 0.07030615185648602\n",
      "R^2 Score: 0.8313842155646438\n",
      "************************\n",
      " avilamycin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6943 - mse: 5.6389e-04\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6933 - mse: 8.9949e-05\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - mse: 7.9711e-05\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6934 - mse: 1.2900e-04\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6934 - mse: 1.2947e-04\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - mse: 8.7833e-05\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6932 - mse: 3.9092e-05\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6932 - mse: 1.3870e-05\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - mse: 7.5761e-06\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6932 - mse: 1.9292e-05\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6937 - mse: 2.9953e-04\n",
      "Loss: 0.6937466263771057\n",
      "Mean Squared Error: 0.00029952547629363835\n",
      "len of pred:  (1, 1) y_test:  (1,)\n",
      "Mean Squared Error: 0.00029952548743494845\n",
      "Mean Absolute Error: 0.017306804656982422\n",
      "R^2 Score: nan\n",
      "************************\n",
      " amoxicillin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:589: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6668 - mse: 0.2247\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.6168 - mse: 0.1998\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5670 - mse: 0.1754\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.5143 - mse: 0.1505\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4558 - mse: 0.1240\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.3965 - mse: 0.0991\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3376 - mse: 0.0766\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2860 - mse: 0.0592\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 964us/step - loss: 0.2467 - mse: 0.0478\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2180 - mse: 0.0402\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.1928 - mse: 0.0278\n",
      "Loss: 0.19277428090572357\n",
      "Mean Squared Error: 0.027843814343214035\n",
      "len of pred:  (47, 1) y_test:  (47,)\n",
      "Mean Squared Error: 0.027843814132731775\n",
      "Mean Absolute Error: 0.12356298908274224\n",
      "R^2 Score: 0.8232557890252744\n",
      "************************\n",
      " enrofloxacin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6858 - mse: 0.1781\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6748 - mse: 0.1726\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6642 - mse: 0.1674\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6561 - mse: 0.1633\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6473 - mse: 0.1589\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6368 - mse: 0.1537\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6264 - mse: 0.1485\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6148 - mse: 0.1428\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6026 - mse: 0.1368\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5900 - mse: 0.1306\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5893 - mse: 0.1152\n",
      "Loss: 0.5893208384513855\n",
      "Mean Squared Error: 0.11522936820983887\n",
      "len of pred:  (3, 1) y_test:  (3,)\n",
      "Mean Squared Error: 0.11522936966283599\n",
      "Mean Absolute Error: 0.28337250153223675\n",
      "R^2 Score: -1.0741286539310475\n",
      "************************\n",
      " doxycycline\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6719 - mse: 0.1959\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6401 - mse: 0.1804\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 832us/step - loss: 0.6139 - mse: 0.1681\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.5929 - mse: 0.1590\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 824us/step - loss: 0.5739 - mse: 0.1512\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5561 - mse: 0.1439\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 996us/step - loss: 0.5400 - mse: 0.1376\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5223 - mse: 0.1308\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.5034 - mse: 0.1232\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4847 - mse: 0.1154\n",
      "WARNING:tensorflow:5 out of the last 39 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA8B45EDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.4546 - mse: 0.1023\n",
      "Loss: 0.4545571804046631\n",
      "Mean Squared Error: 0.10229488462209702\n",
      "len of pred:  (47, 1) y_test:  (47,)\n",
      "Mean Squared Error: 0.10229488087620871\n",
      "Mean Absolute Error: 0.26474577251901016\n",
      "R^2 Score: 0.3506626670817672\n",
      "************************\n",
      " omadacycline\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6940 - mse: 0.1879\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6833 - mse: 0.1826\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.6739 - mse: 0.1779\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6657 - mse: 0.1738\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6575 - mse: 0.1697\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6493 - mse: 0.1657\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6414 - mse: 0.1618\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6334 - mse: 0.1578\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6259 - mse: 0.1541\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 958us/step - loss: 0.6179 - mse: 0.1502\n",
      "WARNING:tensorflow:6 out of the last 41 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA93372A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7502 - mse: 0.1534\n",
      "Loss: 0.7502371668815613\n",
      "Mean Squared Error: 0.1534317284822464\n",
      "len of pred:  (2, 1) y_test:  (2,)\n",
      "Mean Squared Error: 0.15343172805973282\n",
      "Mean Absolute Error: 0.282504141330719\n",
      "R^2 Score: -1.454907648955725\n",
      "************************\n",
      " tedizolid\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.7310 - mse: 0.2439\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7164 - mse: 0.2366\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7077 - mse: 0.2323\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.7019 - mse: 0.2294\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6960 - mse: 0.2264\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6901 - mse: 0.2235\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6843 - mse: 0.2206\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6777 - mse: 0.2173\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6701 - mse: 0.2135\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6610 - mse: 0.2090\n",
      "WARNING:tensorflow:7 out of the last 42 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA9487DE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6794 - mse: 0.2431\n",
      "Loss: 0.6793636679649353\n",
      "Mean Squared Error: 0.24311192333698273\n",
      "len of pred:  (5, 1) y_test:  (5,)\n",
      "Mean Squared Error: 0.24311192000358056\n",
      "Mean Absolute Error: 0.49291799068450926\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " bacitracin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7485 - mse: 0.0260\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7321 - mse: 0.0186\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.7210 - mse: 0.0134\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7134 - mse: 0.0098\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7078 - mse: 0.0072\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7043 - mse: 0.0055\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7017 - mse: 0.0042\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6995 - mse: 0.0032\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6978 - mse: 0.0023\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6966 - mse: 0.0017\n",
      "WARNING:tensorflow:8 out of the last 43 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA8DEB6EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6945 - mse: 6.7013e-04\n",
      "Loss: 0.6944892406463623\n",
      "Mean Squared Error: 0.0006701312377117574\n",
      "len of pred:  (1, 1) y_test:  (1,)\n",
      "Mean Squared Error: 0.0006701312432966233\n",
      "Mean Absolute Error: 0.025886893272399902\n",
      "R^2 Score: nan\n",
      "************************\n",
      " mupirocin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:589: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 998us/step - loss: 0.6406 - mse: 0.1678\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.5770 - mse: 0.1373\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 928us/step - loss: 0.5155 - mse: 0.1106\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.4612 - mse: 0.0904\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.4225 - mse: 0.0778\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3899 - mse: 0.0661\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.3638 - mse: 0.0570\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3449 - mse: 0.0505\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3266 - mse: 0.0437\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3126 - mse: 0.0391\n",
      "WARNING:tensorflow:9 out of the last 44 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA9042AA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4596 - mse: 0.0729WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4854 - mse: 0.0787\n",
      "Loss: 0.485422819852829\n",
      "Mean Squared Error: 0.0786757618188858\n",
      "len of pred:  (79, 1) y_test:  (79,)\n",
      "Mean Squared Error: 0.07867576339058979\n",
      "Mean Absolute Error: 0.1999812092207655\n",
      "R^2 Score: 0.48530876381481036\n",
      "************************\n",
      " spectinomycin\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5755 - mse: 0.1888\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 888us/step - loss: 0.3249 - mse: 0.0762\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1220 - mse: 0.0139\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0354 - mse: 0.0015\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 4.9124e-04\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0132 - mse: 2.6824e-04\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0118 - mse: 1.8015e-04\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0111 - mse: 1.2488e-04\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 9.0721e-05\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0104 - mse: 6.9492e-05\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA8B897040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 0s 988us/step - loss: 0.0379 - mse: 0.0027\n",
      "Loss: 0.0378851555287838\n",
      "Mean Squared Error: 0.002661979291588068\n",
      "len of pred:  (97, 1) y_test:  (97,)\n",
      "Mean Squared Error: 0.0026619794037431453\n",
      "Mean Absolute Error: 0.008866408894729042\n",
      "R^2 Score: 0.7306821052707606\n",
      "************************\n",
      " eravacycline\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8329 - mse: 0.1935\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.7997 - mse: 0.1776\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 956us/step - loss: 0.7717 - mse: 0.1640\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.7493 - mse: 0.1530\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.7292 - mse: 0.1430\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7132 - mse: 0.1350\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6999 - mse: 0.1284\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6868 - mse: 0.1218\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6747 - mse: 0.1158\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6683 - mse: 0.1126\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CACE761E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 957us/step - loss: 0.6934 - mse: 1.3899e-04\n",
      "Loss: 0.6934252381324768\n",
      "Mean Squared Error: 0.00013898671022616327\n",
      "len of pred:  (1, 1) y_test:  (1,)\n",
      "Mean Squared Error: 0.0001389867054548688\n",
      "Mean Absolute Error: 0.011789262294769287\n",
      "R^2 Score: nan\n",
      "************************\n",
      " meropenem-vaborbactam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:589: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.7406 - mse: 0.2736\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6865 - mse: 0.2467\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.6603 - mse: 0.2336\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6404 - mse: 0.2237\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6168 - mse: 0.2120\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 859us/step - loss: 0.5878 - mse: 0.1978\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5528 - mse: 0.1810\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.5097 - mse: 0.1607\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 855us/step - loss: 0.4649 - mse: 0.1406\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4187 - mse: 0.1209\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CABD2F1DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 968us/step - loss: 0.4675 - mse: 0.1339\n",
      "Loss: 0.4674932062625885\n",
      "Mean Squared Error: 0.13394354283809662\n",
      "len of pred:  (25, 1) y_test:  (25,)\n",
      "Mean Squared Error: 0.13394353771211884\n",
      "Mean Absolute Error: 0.33984372854232786\n",
      "R^2 Score: -0.6742942214014853\n",
      "************************\n",
      " cefamandole\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9229 - mse: 0.3630\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8985 - mse: 0.3513\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.8751 - mse: 0.3399\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8535 - mse: 0.3294\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.8342 - mse: 0.3200\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8174 - mse: 0.3118\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.8016 - mse: 0.3040\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7862 - mse: 0.2964\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.7714 - mse: 0.2890\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.7575 - mse: 0.2821\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA8D297940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8011 - mse: 0.3038\n",
      "Loss: 0.8010504841804504\n",
      "Mean Squared Error: 0.3037584125995636\n",
      "len of pred:  (1, 1) y_test:  (1,)\n",
      "Mean Squared Error: 0.3037583989714818\n",
      "Mean Absolute Error: 0.5511428117752075\n",
      "R^2 Score: nan\n",
      "************************\n",
      " synercid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:589: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.7187 - mse: 0.2627\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 889us/step - loss: 0.6468 - mse: 0.2269\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6085 - mse: 0.2078\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 808us/step - loss: 0.5769 - mse: 0.1923\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.5359 - mse: 0.1724\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 990us/step - loss: 0.4830 - mse: 0.1474\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4217 - mse: 0.1198\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 806us/step - loss: 0.3551 - mse: 0.0916\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2847 - mse: 0.0648\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 858us/step - loss: 0.2186 - mse: 0.0424\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA8F296430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.1834 - mse: 0.0322\n",
      "Loss: 0.18343107402324677\n",
      "Mean Squared Error: 0.0322054959833622\n",
      "len of pred:  (34, 1) y_test:  (34,)\n",
      "Mean Squared Error: 0.032205495658900955\n",
      "Mean Absolute Error: 0.1646291683701908\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " trimethoprim-sulfamethoxazole\n",
      "Epoch 1/10\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 0.1459 - mse: 0.0401\n",
      "Epoch 2/10\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 0.0663 - mse: 0.0153\n",
      "Epoch 3/10\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 0.0563 - mse: 0.0124\n",
      "Epoch 4/10\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 0.0514 - mse: 0.0112\n",
      "Epoch 5/10\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 0.0482 - mse: 0.0105\n",
      "Epoch 6/10\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 0.0462 - mse: 0.0101\n",
      "Epoch 7/10\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 0.0432 - mse: 0.0094\n",
      "Epoch 8/10\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 0.0408 - mse: 0.0086\n",
      "Epoch 9/10\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 0.0403 - mse: 0.0086\n",
      "Epoch 10/10\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 0.0393 - mse: 0.0084\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CACF7BEAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "104/104 [==============================] - 0s 861us/step - loss: 0.0830 - mse: 0.0173\n",
      "Loss: 0.08303695917129517\n",
      "Mean Squared Error: 0.017328497022390366\n",
      "len of pred:  (3311, 1) y_test:  (3311,)\n",
      "Mean Squared Error: 0.01732849688766331\n",
      "Mean Absolute Error: 0.031115396452138993\n",
      "R^2 Score: 0.872344365858622\n",
      "************************\n",
      " aztreonam\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.4262 - mse: 0.1316\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1987 - mse: 0.0512\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1573 - mse: 0.0389\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1296 - mse: 0.0306\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1134 - mse: 0.0252\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1027 - mse: 0.0225\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0939 - mse: 0.0195\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0859 - mse: 0.0174\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0819 - mse: 0.0158\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0804 - mse: 0.0157\n",
      "27/27 [==============================] - 0s 858us/step - loss: 0.2342 - mse: 0.0533\n",
      "Loss: 0.2341720312833786\n",
      "Mean Squared Error: 0.05329693853855133\n",
      "len of pred:  (847, 1) y_test:  (847,)\n",
      "Mean Squared Error: 0.05329693509274234\n",
      "Mean Absolute Error: 0.08588786844225493\n",
      "R^2 Score: 0.7757515811294078\n",
      "************************\n",
      " norfloxacin\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6682 - mse: 0.2094\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.6465 - mse: 0.1987\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.6241 - mse: 0.1876\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.5981 - mse: 0.1748\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.5671 - mse: 0.1600\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5367 - mse: 0.1459\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.5117 - mse: 0.1348\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.4810 - mse: 0.1218\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.4554 - mse: 0.1118\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4308 - mse: 0.1028\n",
      "1/1 [==============================] - 0s 985us/step - loss: 0.4511 - mse: 0.1409\n",
      "Loss: 0.4510737359523773\n",
      "Mean Squared Error: 0.14088879525661469\n",
      "len of pred:  (23, 1) y_test:  (23,)\n",
      "Mean Squared Error: 0.14088879370662402\n",
      "Mean Absolute Error: 0.31327129706092505\n",
      "R^2 Score: 0.17188697921328766\n",
      "************************\n",
      " neomycin\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6849 - mse: 0.0584\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6778 - mse: 0.0549\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6722 - mse: 0.0521\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6671 - mse: 0.0496\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6625 - mse: 0.0473\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 964us/step - loss: 0.6586 - mse: 0.0455\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6548 - mse: 0.0437\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6510 - mse: 0.0419\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6472 - mse: 0.0401\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6434 - mse: 0.0384\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5894 - mse: 0.1376\n",
      "Loss: 0.589438796043396\n",
      "Mean Squared Error: 0.1375708431005478\n",
      "len of pred:  (4, 1) y_test:  (4,)\n",
      "Mean Squared Error: 0.13757084888058024\n",
      "Mean Absolute Error: 0.3178057372570038\n",
      "R^2 Score: -1.934844776119045\n",
      "************************\n",
      " Imipenem-EDTA-PA\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.7010 - mse: 0.0039\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.6944 - mse: 6.0168e-04\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6937 - mse: 2.7062e-04\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6936 - mse: 2.2386e-04\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 993us/step - loss: 0.6935 - mse: 1.7217e-04\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 661us/step - loss: 0.6934 - mse: 1.2251e-04\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.6933 - mse: 8.5947e-05\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 665us/step - loss: 0.6933 - mse: 5.8829e-05\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.6932 - mse: 4.1413e-05\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6932 - mse: 3.0285e-05\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6932 - mse: 2.4872e-05\n",
      "Loss: 0.6931968927383423\n",
      "Mean Squared Error: 2.4871527784853242e-05\n",
      "len of pred:  (17, 1) y_test:  (17,)\n",
      "Mean Squared Error: 2.4871526399242663e-05\n",
      "Mean Absolute Error: 0.003312133690890144\n",
      "R^2 Score: 0.0\n",
      "************************\n",
      " delafloxacin\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.7093 - mse: 0.2581\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6887 - mse: 0.2478\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6758 - mse: 0.2413\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6693 - mse: 0.2381\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6596 - mse: 0.2333\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6508 - mse: 0.2290\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6407 - mse: 0.2240\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6315 - mse: 0.2195\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6200 - mse: 0.2139\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.6081 - mse: 0.2082\n",
      "WARNING:tensorflow:5 out of the last 31 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CAAFE944C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 952us/step - loss: 0.6757 - mse: 0.2414\n",
      "Loss: 0.6756774187088013\n",
      "Mean Squared Error: 0.24139179289340973\n",
      "len of pred:  (13, 1) y_test:  (13,)\n",
      "Mean Squared Error: 0.24139178755820723\n",
      "Mean Absolute Error: 0.48714261788588303\n",
      "R^2 Score: -0.019880302433425312\n",
      "************************\n",
      " zoliflodacin\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 914us/step - loss: 0.6932 - mse: 3.3966e-05\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 769us/step - loss: 0.6932 - mse: 7.3409e-06\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 914us/step - loss: 0.6932 - mse: 2.8026e-06\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6932 - mse: 1.9814e-06\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 831us/step - loss: 0.6931 - mse: 1.1309e-06\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.6931 - mse: 8.3862e-07\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 965us/step - loss: 0.6931 - mse: 6.8147e-07\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 936us/step - loss: 0.6931 - mse: 5.2955e-07\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6931 - mse: 4.0479e-07\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6931 - mse: 3.4479e-07\n",
      "WARNING:tensorflow:6 out of the last 32 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA8D969430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.6932 - mse: 0.0028\n",
      "Loss: 0.6931594014167786\n",
      "Mean Squared Error: 0.0027533583343029022\n",
      "len of pred:  (91, 1) y_test:  (91,)\n",
      "Mean Squared Error: 0.002753358463932689\n",
      "Mean Absolute Error: 0.006092990820224469\n",
      "R^2 Score: -0.013358286214515847\n",
      "************************\n",
      " vancomycin\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 0s 997us/step - loss: 0.5737 - mse: 0.1897\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 997us/step - loss: 0.3310 - mse: 0.0867\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.2076 - mse: 0.0497\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 0s 993us/step - loss: 0.1502 - mse: 0.0385\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1145 - mse: 0.0309\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0913 - mse: 0.0256\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0746 - mse: 0.0206\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0615 - mse: 0.0164\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0517 - mse: 0.0132\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0436 - mse: 0.0106\n",
      "WARNING:tensorflow:7 out of the last 35 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CA93979A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "6/6 [==============================] - 0s 991us/step - loss: 0.0972 - mse: 0.0276\n",
      "Loss: 0.0971742495894432\n",
      "Mean Squared Error: 0.027579715475440025\n",
      "len of pred:  (168, 1) y_test:  (168,)\n",
      "Mean Squared Error: 0.02757971250320897\n",
      "Mean Absolute Error: 0.0440089569379604\n",
      "R^2 Score: 0.422115957171069\n",
      "************************\n",
      " ertapenem\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.3665 - mse: 0.1056\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1791 - mse: 0.0444\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1421 - mse: 0.0323\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1203 - mse: 0.0256\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.1137 - mse: 0.0240\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.0985 - mse: 0.0197\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.0932 - mse: 0.0184\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.0870 - mse: 0.0170\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.0828 - mse: 0.0162\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 0.0769 - mse: 0.0145\n",
      "26/26 [==============================] - 0s 805us/step - loss: 0.1795 - mse: 0.0402\n",
      "Loss: 0.1795141100883484\n",
      "Mean Squared Error: 0.040204375982284546\n",
      "len of pred:  (807, 1) y_test:  (807,)\n",
      "Mean Squared Error: 0.04020437370969866\n",
      "Mean Absolute Error: 0.06433035466184822\n",
      "R^2 Score: 0.7332097882223786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      " cefiderocol\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8311 - mse: 0.3009\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.7956 - mse: 0.2838\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.7665 - mse: 0.2696\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 959us/step - loss: 0.7414 - mse: 0.2573\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 957us/step - loss: 0.7214 - mse: 0.2474\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7110 - mse: 0.2422\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7039 - mse: 0.2387\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6984 - mse: 0.2360\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6935 - mse: 0.2336\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6887 - mse: 0.2311\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7283 - mse: 0.2675\n",
      "Loss: 0.7282583713531494\n",
      "Mean Squared Error: 0.2675324082374573\n",
      "len of pred:  (4, 1) y_test:  (4,)\n",
      "Mean Squared Error: 0.2675323857098224\n",
      "Mean Absolute Error: 0.5170634984970093\n",
      "R^2 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "antibiotic_one_sample = []\n",
    "for antibiotic in unique_all_antibiotics:\n",
    "    if len(df[df['drug'] == antibiotic]) == 1:\n",
    "        antibiotic_one_sample.append(antibiotic)\n",
    "        continue\n",
    "    PredR_Antibiotic(antibiotic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dicloxacillin',\n",
       " 'fosfomycin-glucose-6-phosphate',\n",
       " 'fidaxomicin',\n",
       " 'apramycin',\n",
       " 'cephalexin',\n",
       " 'ceftizoxime',\n",
       " 'surotomycin',\n",
       " 'rifaximin',\n",
       " 'pefloxacin',\n",
       " 'mecillinam']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antibiotic_one_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chloramphenicol</th>\n",
       "      <th>dicloxacillin</th>\n",
       "      <th>ciprofloxacin</th>\n",
       "      <th>ceftiofur</th>\n",
       "      <th>fosfomycin-glucose-6-phosphate</th>\n",
       "      <th>amoxicillin-clavulanic acid</th>\n",
       "      <th>benzylpenicillin</th>\n",
       "      <th>metronidazole</th>\n",
       "      <th>linezolid</th>\n",
       "      <th>piperacillin</th>\n",
       "      <th>...</th>\n",
       "      <th>trimethoprim-sulfamethoxazole</th>\n",
       "      <th>aztreonam</th>\n",
       "      <th>norfloxacin</th>\n",
       "      <th>neomycin</th>\n",
       "      <th>Imipenem-EDTA-PA</th>\n",
       "      <th>delafloxacin</th>\n",
       "      <th>zoliflodacin</th>\n",
       "      <th>vancomycin</th>\n",
       "      <th>ertapenem</th>\n",
       "      <th>cefiderocol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qnrB48</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.039699</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041179</td>\n",
       "      <td>0.282364</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.501277</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.655702</td>\n",
       "      <td>0.504569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blaADC-155</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004928</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oqxB19</th>\n",
       "      <td>0.017815</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.022884</td>\n",
       "      <td>0.121675</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.017955</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.058612</td>\n",
       "      <td>0.567754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111477</td>\n",
       "      <td>0.136410</td>\n",
       "      <td>0.426273</td>\n",
       "      <td>0.533598</td>\n",
       "      <td>0.503210</td>\n",
       "      <td>0.510799</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.049670</td>\n",
       "      <td>0.116142</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blaACT-37</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.356468</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.681791</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.514734</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blaTEM-19</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.124477</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010286</td>\n",
       "      <td>0.071376</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.523927</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.075586</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blaOXA-494</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.422314</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.551732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>0.102046</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.501589</td>\n",
       "      <td>0.521212</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.093444</td>\n",
       "      <td>0.498074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qnrB38</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.693029</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007532</td>\n",
       "      <td>0.047051</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.289587</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmexD3</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.039345</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tet(O)</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murA_D278E</th>\n",
       "      <td>0.064570</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.062305</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.512381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.037204</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            chloramphenicol  dicloxacillin  ciprofloxacin  ceftiofur  \\\n",
       "qnrB48            -1.000000             -1       0.039699  -1.000000   \n",
       "blaADC-155        -1.000000             -1       0.006509  -1.000000   \n",
       "oqxB19             0.017815             -1       0.022884   0.121675   \n",
       "blaACT-37         -1.000000             -1       0.004970  -1.000000   \n",
       "blaTEM-19         -1.000000             -1       0.004653  -1.000000   \n",
       "...                     ...            ...            ...        ...   \n",
       "blaOXA-494        -1.000000             -1       0.017026  -1.000000   \n",
       "qnrB38            -1.000000             -1       0.002331  -1.000000   \n",
       "tmexD3            -1.000000             -1       0.039345  -1.000000   \n",
       "tet(O)            -1.000000             -1       0.009538  -1.000000   \n",
       "murA_D278E         0.064570             -1       0.004425  -1.000000   \n",
       "\n",
       "            fosfomycin-glucose-6-phosphate  amoxicillin-clavulanic acid  \\\n",
       "qnrB48                                  -1                    -1.000000   \n",
       "blaADC-155                              -1                    -1.000000   \n",
       "oqxB19                                  -1                     0.017955   \n",
       "blaACT-37                               -1                     0.356468   \n",
       "blaTEM-19                               -1                     0.124477   \n",
       "...                                    ...                          ...   \n",
       "blaOXA-494                              -1                     0.422314   \n",
       "qnrB38                                  -1                     0.693029   \n",
       "tmexD3                                  -1                    -1.000000   \n",
       "tet(O)                                  -1                     0.002270   \n",
       "murA_D278E                              -1                    -1.000000   \n",
       "\n",
       "            benzylpenicillin  metronidazole  linezolid  piperacillin  ...  \\\n",
       "qnrB48                  -1.0           -1.0  -1.000000     -1.000000  ...   \n",
       "blaADC-155              -1.0           -1.0  -1.000000     -1.000000  ...   \n",
       "oqxB19                  -1.0           -1.0   0.058612      0.567754  ...   \n",
       "blaACT-37               -1.0           -1.0  -1.000000     -1.000000  ...   \n",
       "blaTEM-19               -1.0           -1.0  -1.000000     -1.000000  ...   \n",
       "...                      ...            ...        ...           ...  ...   \n",
       "blaOXA-494              -1.0           -1.0  -1.000000      0.551732  ...   \n",
       "qnrB38                  -1.0           -1.0  -1.000000     -1.000000  ...   \n",
       "tmexD3                  -1.0           -1.0  -1.000000     -1.000000  ...   \n",
       "tet(O)                  -1.0           -1.0  -1.000000     -1.000000  ...   \n",
       "murA_D278E              -1.0           -1.0   0.062305     -1.000000  ...   \n",
       "\n",
       "            trimethoprim-sulfamethoxazole  aztreonam  norfloxacin  neomycin  \\\n",
       "qnrB48                           0.041179   0.282364    -1.000000 -1.000000   \n",
       "blaADC-155                       0.004928  -1.000000    -1.000000 -1.000000   \n",
       "oqxB19                           0.111477   0.136410     0.426273  0.533598   \n",
       "blaACT-37                        0.007567   0.681791    -1.000000 -1.000000   \n",
       "blaTEM-19                        0.010286   0.071376    -1.000000 -1.000000   \n",
       "...                                   ...        ...          ...       ...   \n",
       "blaOXA-494                       0.034108   0.102046    -1.000000 -1.000000   \n",
       "qnrB38                           0.007532   0.047051    -1.000000 -1.000000   \n",
       "tmexD3                          -1.000000  -1.000000    -1.000000 -1.000000   \n",
       "tet(O)                          -1.000000  -1.000000    -1.000000 -1.000000   \n",
       "murA_D278E                       0.003428  -1.000000    -1.000000 -1.000000   \n",
       "\n",
       "            Imipenem-EDTA-PA  delafloxacin  zoliflodacin  vancomycin  \\\n",
       "qnrB48              0.501277      0.519180          -1.0   -1.000000   \n",
       "blaADC-155         -1.000000     -1.000000          -1.0   -1.000000   \n",
       "oqxB19              0.503210      0.510799          -1.0    0.049670   \n",
       "blaACT-37          -1.000000     -1.000000          -1.0   -1.000000   \n",
       "blaTEM-19          -1.000000      0.523927          -1.0   -1.000000   \n",
       "...                      ...           ...           ...         ...   \n",
       "blaOXA-494          0.501589      0.521212          -1.0   -1.000000   \n",
       "qnrB38             -1.000000     -1.000000          -1.0   -1.000000   \n",
       "tmexD3             -1.000000     -1.000000          -1.0   -1.000000   \n",
       "tet(O)             -1.000000     -1.000000          -1.0   -1.000000   \n",
       "murA_D278E         -1.000000      0.512381          -1.0    0.037204   \n",
       "\n",
       "            ertapenem  cefiderocol  \n",
       "qnrB48       0.655702     0.504569  \n",
       "blaADC-155  -1.000000    -1.000000  \n",
       "oqxB19       0.116142    -1.000000  \n",
       "blaACT-37    0.514734    -1.000000  \n",
       "blaTEM-19    0.075586    -1.000000  \n",
       "...               ...          ...  \n",
       "blaOXA-494   0.093444     0.498074  \n",
       "qnrB38       0.289587    -1.000000  \n",
       "tmexD3      -1.000000    -1.000000  \n",
       "tet(O)      -1.000000    -1.000000  \n",
       "murA_D278E  -1.000000    -1.000000  \n",
       "\n",
       "[1213 rows x 114 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_antibiotic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model - accuraccy & MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00322947],\n",
       "       [0.9983469 ],\n",
       "       [0.00322947],\n",
       "       ...,\n",
       "       [0.00265715],\n",
       "       [0.00217324],\n",
       "       [0.0024083 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation - continues (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.01619927366086918\n",
      "Mean Absolute Error: 0.03154599644390347\n",
      "R^2 Score: 0.8993035344650906\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one examle test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99743843]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[1].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for each Gene seperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qnrB48</th>\n",
       "      <th>blaADC-155</th>\n",
       "      <th>oqxB19</th>\n",
       "      <th>blaACT-37</th>\n",
       "      <th>blaTEM-19</th>\n",
       "      <th>cmx</th>\n",
       "      <th>rmtF2</th>\n",
       "      <th>blaCTX-M-24</th>\n",
       "      <th>qnrB77</th>\n",
       "      <th>blaOXY-2-6</th>\n",
       "      <th>...</th>\n",
       "      <th>gyrA_D95N</th>\n",
       "      <th>mgrB_M27K</th>\n",
       "      <th>blaCDD</th>\n",
       "      <th>blaOXA-735</th>\n",
       "      <th>pmrB_T140P</th>\n",
       "      <th>blaOXA-494</th>\n",
       "      <th>qnrB38</th>\n",
       "      <th>tmexD3</th>\n",
       "      <th>tet(O)</th>\n",
       "      <th>murA_D278E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1104 rows × 1104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      qnrB48  blaADC-155  oqxB19  blaACT-37  blaTEM-19  cmx  rmtF2  \\\n",
       "0          1           0       0          0          0    0      0   \n",
       "1          0           1       0          0          0    0      0   \n",
       "2          0           0       1          0          0    0      0   \n",
       "3          0           0       0          1          0    0      0   \n",
       "4          0           0       0          0          1    0      0   \n",
       "...      ...         ...     ...        ...        ...  ...    ...   \n",
       "1099       0           0       0          0          0    0      0   \n",
       "1100       0           0       0          0          0    0      0   \n",
       "1101       0           0       0          0          0    0      0   \n",
       "1102       0           0       0          0          0    0      0   \n",
       "1103       0           0       0          0          0    0      0   \n",
       "\n",
       "      blaCTX-M-24  qnrB77  blaOXY-2-6  ...  gyrA_D95N  mgrB_M27K  blaCDD  \\\n",
       "0               0       0           0  ...          0          0       0   \n",
       "1               0       0           0  ...          0          0       0   \n",
       "2               0       0           0  ...          0          0       0   \n",
       "3               0       0           0  ...          0          0       0   \n",
       "4               0       0           0  ...          0          0       0   \n",
       "...           ...     ...         ...  ...        ...        ...     ...   \n",
       "1099            0       0           0  ...          0          0       0   \n",
       "1100            0       0           0  ...          0          0       0   \n",
       "1101            0       0           0  ...          0          0       0   \n",
       "1102            0       0           0  ...          0          0       0   \n",
       "1103            0       0           0  ...          0          0       0   \n",
       "\n",
       "      blaOXA-735  pmrB_T140P  blaOXA-494  qnrB38  tmexD3  tet(O)  murA_D278E  \n",
       "0              0           0           0       0       0       0           0  \n",
       "1              0           0           0       0       0       0           0  \n",
       "2              0           0           0       0       0       0           0  \n",
       "3              0           0           0       0       0       0           0  \n",
       "4              0           0           0       0       0       0           0  \n",
       "...          ...         ...         ...     ...     ...     ...         ...  \n",
       "1099           0           0           1       0       0       0           0  \n",
       "1100           0           0           0       1       0       0           0  \n",
       "1101           0           0           0       0       1       0           0  \n",
       "1102           0           0           0       0       0       1           0  \n",
       "1103           0           0           0       0       0       0           1  \n",
       "\n",
       "[1104 rows x 1104 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gene = model.predict(df_one_gene)\n",
    "data = pd.DataFrame(data=pred_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>0.016005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>0.049610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>0.007509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>0.003196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1104 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.062887\n",
       "1     0.002434\n",
       "2     0.015267\n",
       "3     0.001975\n",
       "4     0.001146\n",
       "...        ...\n",
       "1099  0.016005\n",
       "1100  0.001224\n",
       "1101  0.049610\n",
       "1102  0.007509\n",
       "1103  0.003196\n",
       "\n",
       "[1104 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blaADC-155\n"
     ]
    }
   ],
   "source": [
    "genes_list = list(oxacillin_genes)\n",
    "\n",
    "# Access the element at index 29\n",
    "gene_at_index = genes_list[1]\n",
    "\n",
    "print(gene_at_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.642578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.824058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.997132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.636477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.988201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.888557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.908533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.604366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.978971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.639507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.705829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.997383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.545639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.942927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.674326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.606528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.932008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.778902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.936840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.779326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.957187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.947881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0.831975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0.852590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>0.867928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.621986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0.767710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.859715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>0.791142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.896220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>0.810195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.897296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.801686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0.946633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0.617905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0.781602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.776211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>0.902549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.839257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>0.530475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>0.936893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>0.663888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0.762889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>0.550063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>0.837561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "8     0.642578\n",
       "12    0.824058\n",
       "29    0.997132\n",
       "42    0.636477\n",
       "90    0.988201\n",
       "95    0.888557\n",
       "146   0.908533\n",
       "150   0.604366\n",
       "195   0.978971\n",
       "227   0.639507\n",
       "240   0.705829\n",
       "273   0.997383\n",
       "293   0.545639\n",
       "311   0.942927\n",
       "363   0.674326\n",
       "374   0.606528\n",
       "384   0.932008\n",
       "396   0.778902\n",
       "428   0.936840\n",
       "453   0.706250\n",
       "454   0.779326\n",
       "466   0.957187\n",
       "558   0.947881\n",
       "584   0.831975\n",
       "628   0.852590\n",
       "713   0.867928\n",
       "724   0.621986\n",
       "762   0.767710\n",
       "775   0.859715\n",
       "787   0.791142\n",
       "797   0.896220\n",
       "821   0.810195\n",
       "829   0.897296\n",
       "862   0.801686\n",
       "873   0.946633\n",
       "874   0.617905\n",
       "893   0.781602\n",
       "919   0.776211\n",
       "925   0.902549\n",
       "977   0.839257\n",
       "1005  0.530475\n",
       "1028  0.936893\n",
       "1050  0.663888\n",
       "1064  0.762889\n",
       "1080  0.550063\n",
       "1083  0.837561"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data=pred_gene)\n",
    "data[data > 0.5].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973835"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_gene.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4436484e-05"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_gene.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going over all the bacteria that are resistant to \"chloramphenicol\":\n",
    "for gene_lst in df[(df.drug == \"ciprofloxacin\") & (df.resistance == 0)]['AMR genotypes'].values:\n",
    "# going over all the genes of each bacteria :\n",
    "    for g in gene_lst.split():\n",
    "        print(g)\n",
    "        v = np.zeros(X.shape[1])\n",
    "        v[feature_names.index(g)]=1\n",
    "        print(classifier.predict_proba([v]))\n",
    "    print(\"***************************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}